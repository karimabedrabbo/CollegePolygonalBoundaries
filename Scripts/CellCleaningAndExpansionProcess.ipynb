{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#             this_el = s2.CellUnion(map(lambda x: s2.CellId.from_token(x), element.get('cover16s')))\n",
    "#             dict_el = s2.CellUnion(map(lambda x: s2.CellId.from_token(x), l_dict[token].get('cover16s')))\n",
    "\n",
    "#             intersection = list(map(lambda x: x.to_token(), s2.CellUnion.get_intersection(this_el, dict_el).cell_ids()))\n",
    "#             difference = list(map(lambda x: x.to_token(), s2.CellUnion.get_difference(this_el, dict_el).cell_ids()))\n",
    "            \n",
    "#             if len(intersection) < len(difference):\n",
    "                \n",
    "#                 bad_count +=1\n",
    "#                 print(element.get('name'))\n",
    "#                 print(l_dict[token].get('name'))\n",
    "                \n",
    "#             if s2.CellUnion.get_intersection(a,b).cell_ids():\n",
    "#                 bad_count +=1\n",
    "#             if (a.get_rect_bound().interior_contains((b.get_rect_bound().get_center())) or b.get_rect_bound().interior_contains((a.get_rect_bound().get_center()))):\n",
    "#                 bad_count +=1\n",
    "#                 print(element.get('name'))\n",
    "#                 print(l_dict[token].get('name'))\n",
    "#                 if bad_count > 10:\n",
    "#                     return\n",
    "\n",
    "          \n",
    "\n",
    "#             for key in n_dict[name].keys():\n",
    "#                 if not key in ['name', 'type', 'nameisid', 'nodelist']:\n",
    "#                     this_el = s2.CellUnion(map(lambda x: s2.CellId.from_token(x), element.get(key)))\n",
    "#                     dict_el = s2.CellUnion(map(lambda x: s2.CellId.from_token(x), n_dict[name].get(key)))\n",
    "#                     new_cell_list = list(map(lambda x: x.to_token(), s2.CellUnion.get_union(this_el, dict_el).cell_ids()))\n",
    "#                     n_dict[name][key] = new_cell_list\n",
    "\n",
    "\n",
    "#             if len(list(map(lambda x: x.to_token(), this_el_16.cell_ids()))) + len(list(map(lambda x: x.to_token(), dict_el_16.cell_ids()))) - len(list(map(lambda x: x.to_token(), s2.CellUnion.get_intersection(this_el_16, dict_el_16).cell_ids()))) != len(new_cell_list_16):\n",
    "#                 print(\"broke\")\n",
    "#                 return\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import s2sphere as s2\n",
    "import copy\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('oldjsonscells/cells_college.json', encoding='utf8') as read_file:\n",
    "    cells_college = json.load(read_file)\n",
    "with open('oldjsonscells/cells_college_bad.json', encoding='utf8') as read_file:\n",
    "    cells_college_bad = json.load(read_file)\n",
    "with open('oldjsonscells/cells_university.json', encoding='utf8') as read_file:\n",
    "    cells_university = json.load(read_file)\n",
    "with open('oldjsonscells/cells_university_bad.json', encoding='utf8') as read_file:\n",
    "    cells_university_bad = json.load(read_file)\n",
    "with open('oldjsonscells/cells_school_bad.json', encoding='utf8') as read_file:\n",
    "    cells_school_bad = json.load(read_file)\n",
    "    \n",
    "cells_school = []\n",
    "for i in range(1000):\n",
    "    with open('oldjsonscells/cells_school_' + str(i) + '.json', encoding='utf8') as read_file:\n",
    "        cells_school.extend(json.load(read_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30193"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cells_college)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cells_university)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_union_preserve_custom(a,b,key):\n",
    "    c = s2.CellUnion.get_union(a, b).cell_ids()\n",
    "    running_union = s2.CellUnion()\n",
    "    for cellId in copy.deepcopy(c):\n",
    "        temp_union = s2.CellUnion([cellId])\n",
    "        min_target = 10\n",
    "        if '10' in key:\n",
    "            min_target = 10\n",
    "        elif '11' in key:\n",
    "            min_target = 11\n",
    "        elif '12' in key:\n",
    "            min_target = 12\n",
    "        elif '13' in key:\n",
    "            min_target = 13\n",
    "        elif '14' in key:\n",
    "            min_target = 14\n",
    "        elif '15' in key:\n",
    "            min_target = 15\n",
    "        elif '16' in key:\n",
    "            min_target = 16\n",
    "        if cellId.level() < min_target:\n",
    "            temp_union = s2.CellUnion(temp_union.denormalize(min_target,1),raw=False)\n",
    "        running_union = s2.CellUnion.get_union(temp_union, running_union,raw=False)\n",
    "    return running_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_name_is_id(all_cells_lists):\n",
    "    all_list = []\n",
    "    int_list = []\n",
    "    for cell_list in all_cells_lists:\n",
    "        for element in cell_list:\n",
    "            try:\n",
    "                int(element.get('name'))\n",
    "                int_list.append(element)\n",
    "            except ValueError:\n",
    "                all_list.append(element)\n",
    "                continue\n",
    "    return all_list, int_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_cells, name_is_id_list = remove_name_is_id([cells_college, cells_college_bad, cells_university, cells_university_bad])\n",
    "total_cells = [cells_college, cells_college_bad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def namecheck(cell_list, name):\n",
    "    for cell in cell_list:\n",
    "        if name in cell['name']:\n",
    "            print(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanInitialSubcategories(all_cells_list):\n",
    "    new_list = []\n",
    "    for all_cells in all_cells_list:\n",
    "        for cell in all_cells:\n",
    "            newcell = copy.deepcopy(cell)\n",
    "            for key in newcell.keys():\n",
    "                if not key in ['name', 'type', 'nameisid', 'nodelist']:\n",
    "                    this_el = s2.CellUnion(map(lambda x: s2.CellId.from_token(x), newcell.get(key)))\n",
    "                    dict_el = s2.CellUnion(map(lambda x: s2.CellId.from_token(x), newcell.get(key)))\n",
    "                    new_cell_list = list(map(lambda x: x.to_token(), get_union_preserve_custom(this_el, dict_el, key).cell_ids()))\n",
    "                    newcell[key] = new_cell_list\n",
    "            new_list.append(newcell)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cells = cleanInitialSubcategories(total_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30219"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformatForName(cell_list):\n",
    "    n_dict = {}\n",
    "    intersects_g = 0\n",
    "    nointersects_g = 0\n",
    "    misfit_list = []\n",
    "    for element in copy.deepcopy(cell_list):\n",
    "        \n",
    "        name = element.get('name')\n",
    "        \n",
    "        if name in n_dict:\n",
    "            \n",
    "            intersects = False\n",
    "            for key in n_dict[name].keys():\n",
    "                if not key in ['name', 'type', 'nameisid', 'nodelist', 'nameisunique']:\n",
    "                    a = s2.CellUnion(map(lambda x: s2.CellId.from_token(x), element.get(key)))\n",
    "                    b = s2.CellUnion(map(lambda x: s2.CellId.from_token(x), n_dict[name].get(key)))\n",
    "                    if s2.CellUnion.get_intersection(a,b).cell_ids():\n",
    "                        intersects = True\n",
    "            if intersects:\n",
    "                intersects_g += 1\n",
    "                for key in n_dict[name].keys():\n",
    "                    if not key in ['name', 'type', 'nameisid', 'nodelist', 'nameisunique']:\n",
    "                        this_el = s2.CellUnion(map(lambda x: s2.CellId.from_token(x), element.get(key)))\n",
    "                        dict_el = s2.CellUnion(map(lambda x: s2.CellId.from_token(x), n_dict[name].get(key)))\n",
    "                        new_cell_list = list(map(lambda x: x.to_token(), get_union_preserve_custom(this_el, dict_el, key).cell_ids()))\n",
    "                        n_dict[name][key] = new_cell_list\n",
    "            else:\n",
    "                nointersects_g += 1\n",
    "#                 if len(misfit_list) < 30:\n",
    "#                     print(element)\n",
    "#                     print(n_dict[name])\n",
    "                misfit_list.append(element)\n",
    "        else:\n",
    "            n_dict[name] = element\n",
    "\n",
    "    print(\"intersects\")\n",
    "    print(intersects_g)\n",
    "    print(\"no_intersects\")\n",
    "    print(nointersects_g)\n",
    "    \n",
    "    finallist = list(n_dict.values())\n",
    "    for element in finallist:\n",
    "        element['nameisunique'] = True\n",
    "    for element in misfit_list:\n",
    "        element['nameisunique'] = False\n",
    "        n_dict[element['name']]['nameisunique'] = False\n",
    "    return finallist + misfit_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersects\n",
      "855\n",
      "no_intersects\n",
      "1622\n"
     ]
    }
   ],
   "source": [
    "total_cells = reformatForName(total_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersects\n",
      "0\n",
      "no_intersects\n",
      "1622\n"
     ]
    }
   ],
   "source": [
    "total_cells = reformatForName(total_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersects\n",
      "0\n",
      "no_intersects\n",
      "1821\n"
     ]
    }
   ],
   "source": [
    "total_cells = reformatForName(total_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cells = reformatForName(total_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cells = reformatForName(total_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(total_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('collegeonly_cells_v2.json', 'w') as write_file:\n",
    "    json.dump(total_cells, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import s2sphere as s2\n",
    "import copy\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new_total_cells_v7.json', 'r', encoding='utf8') as read_file:\n",
    "    total_cells = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29364"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def namecheck(cell_list, name):\n",
    "    for cell in cell_list:\n",
    "        if name in cell['name']:\n",
    "            print(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def namecheckallnames(cell_list, name):\n",
    "    for cell in cell_list:\n",
    "        for evalname in cell['allnames']:\n",
    "            if name in evalname:\n",
    "                print(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def namecheckldict(ldict, name):\n",
    "    for lindex, lkey in enumerate(ldict):\n",
    "        cell = ldict[lkey]\n",
    "        for evalname in cell['allnames']:\n",
    "#             if lindex > 10:\n",
    "#                 return\n",
    "#             print(evalname)\n",
    "            if name in evalname:\n",
    "                print(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addIdIndex(cell_list):\n",
    "    for index, element in enumerate(cell_list):\n",
    "        element['addedindex'] = index\n",
    "    return cell_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cells = addIdIndex(total_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "namecheck(total_cells, 'University of California, Berkeley')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_union_preserve_custom(a,b,key):\n",
    "    c = s2.CellUnion.get_union(a, b).cell_ids()\n",
    "    running_union = s2.CellUnion()\n",
    "    for cellId in copy.deepcopy(c):\n",
    "        temp_union = s2.CellUnion([cellId])\n",
    "        min_target = 10\n",
    "        if '10' in key:\n",
    "            min_target = 10\n",
    "        elif '11' in key:\n",
    "            min_target = 11\n",
    "        elif '12' in key:\n",
    "            min_target = 12\n",
    "        elif '13' in key:\n",
    "            min_target = 13\n",
    "        elif '14' in key:\n",
    "            min_target = 14\n",
    "        elif '15' in key:\n",
    "            min_target = 15\n",
    "        elif '16' in key:\n",
    "            min_target = 16\n",
    "        if cellId.level() < min_target:\n",
    "            temp_union = s2.CellUnion(temp_union.denormalize(min_target,1),raw=False)\n",
    "        running_union = s2.CellUnion.get_union(temp_union, running_union,raw=False)\n",
    "    return running_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformatLocationDict(cell_list):\n",
    "    l_dict = {}\n",
    "    bad_count = 0\n",
    "    for aIndex, element in enumerate(copy.deepcopy(cell_list)):\n",
    "        if aIndex % 1000 == 0:\n",
    "            print(aIndex)\n",
    "            \n",
    "        if 'allnames' not in element:\n",
    "            element['allnames'] = ['%s' % element['name']]\n",
    "                \n",
    "        if 'alladdedindex' not in element:\n",
    "            element['alladdedindex'] = [element['addedindex'] + 0]\n",
    "            \n",
    "        for key in ['name', 'type', 'nameisid', 'nodelist', 'cover10s', 'cover11s', 'cover12s', 'cover13s', 'cover14s', 'cover15s', 'cover10to16', 'cover10and11', 'cover11and12', 'cover12and13', 'cover13and14', 'cover14and15', 'cover15and16', 'nameisunique', 'addedindex']:\n",
    "            element.pop(key, None)\n",
    "                \n",
    "        marklist = []\n",
    "        \n",
    "        #expansion not used atm proves intrusive\n",
    "        #tomark16 = list(map(lambda x: x.to_token(), s2.CellUnion(map(lambda x: s2.CellId.from_token(x), element.get('cover16s')),raw=False).expand(16).cell_ids()))\n",
    "        \n",
    "        for mark_token in element.get('cover16s'):\n",
    "            if mark_token in l_dict and mark_token not in marklist:\n",
    "                marklist.append(mark_token)\n",
    "                \n",
    "        if marklist:\n",
    "            bad_count += 1\n",
    "            \n",
    "            seen_elements = [element]\n",
    "            \n",
    "            #initialize with the current element so its usable in for loop\n",
    "            this_el_16 = s2.CellUnion(map(lambda x: s2.CellId.from_token(x), element.get('cover16s')))\n",
    "            \n",
    "            for marked_tok in marklist:\n",
    "                if l_dict[marked_tok] not in seen_elements:\n",
    "                    seen_elements.append(l_dict[marked_tok])\n",
    "                mark_el_16 = s2.CellUnion(map(lambda x: s2.CellId.from_token(x), l_dict[marked_tok].get('cover16s')))\n",
    "                this_el_16 = get_union_preserve_custom(this_el_16, mark_el_16,'cover16s')\n",
    "                \n",
    "            consider_cell_list_16 = list(map(lambda x: x.to_token(), this_el_16.cell_ids()))\n",
    "              \n",
    "            \n",
    "            control_cell_list_16 = None\n",
    "            \n",
    "            while control_cell_list_16 != consider_cell_list_16:\n",
    "                control_cell_list_16 = copy.deepcopy(consider_cell_list_16)\n",
    "                \n",
    "                for token in consider_cell_list_16:\n",
    "                    search_element = copy.deepcopy(l_dict.get(token))\n",
    "                    if search_element and search_element not in seen_elements:\n",
    "                        seen_elements.append(search_element)\n",
    "                        search_el_16 = s2.CellUnion(map(lambda x: s2.CellId.from_token(x), search_element.get('cover16s')))\n",
    "                        this_el_16 = get_union_preserve_custom(this_el_16, search_el_16,'cover16s')\n",
    "                        \n",
    "                consider_cell_list_16 = list(map(lambda x: x.to_token(), this_el_16.cell_ids()))\n",
    "                        \n",
    "            all_name_set = set()\n",
    "            for name_el in seen_elements:\n",
    "                for curr_name in name_el['allnames']:\n",
    "                    all_name_set.add(curr_name)\n",
    "            \n",
    "            all_id_set = set()\n",
    "            for id_el in seen_elements:\n",
    "                for curr_id in id_el['alladdedindex']:\n",
    "                    all_id_set.add(curr_id)\n",
    "                \n",
    "            new_using_element = {}\n",
    "            new_using_element['cover16s'] = copy.deepcopy(consider_cell_list_16)\n",
    "            new_using_element['allnames'] = copy.deepcopy(list(all_name_set))\n",
    "            new_using_element['alladdedindex'] = copy.deepcopy(list(all_id_set))\n",
    "            \n",
    "            for token in new_using_element['cover16s']:\n",
    "                l_dict[token] = new_using_element\n",
    "        else:   \n",
    "            for token in element.get('cover16s'):\n",
    "                l_dict[token] = copy.deepcopy(element)\n",
    "                \n",
    "                \n",
    "\n",
    "    print(\"badcount\")\n",
    "    print(bad_count)\n",
    "    return l_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "badcount\n",
      "4476\n"
     ]
    }
   ],
   "source": [
    "new_total_cells = reformatLocationDict(total_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "namecheckldict(new_total_cells, 'University of California, Berkeley')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184622"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_total_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformatLocationDictByAddedIndex(cell_location_dict):\n",
    "    indicesseen = set()\n",
    "    reformatlist = []\n",
    "    for tindex, token in enumerate(cell_location_dict):\n",
    "        if(tindex) % 1000 == 0:\n",
    "            print(tindex)\n",
    "        element = cell_location_dict[token]\n",
    "        if not set(element['alladdedindex']).issubset(indicesseen):\n",
    "            reformatlist.append(element)\n",
    "            indicesseen.update(set(element['alladdedindex']))    \n",
    "    return reformatlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "161000\n",
      "162000\n",
      "163000\n",
      "164000\n",
      "165000\n",
      "166000\n",
      "167000\n",
      "168000\n",
      "169000\n",
      "170000\n",
      "171000\n",
      "172000\n",
      "173000\n",
      "174000\n",
      "175000\n",
      "176000\n",
      "177000\n",
      "178000\n",
      "179000\n",
      "180000\n",
      "181000\n",
      "182000\n",
      "183000\n",
      "184000\n"
     ]
    }
   ],
   "source": [
    "total_cells = reformatLocationDictByAddedIndex(new_total_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('collegeonly_cells_v3.json', 'w', encoding='utf8') as write_file:\n",
    "    json.dump(total_cells, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for element in new_total_cells1:\n",
    "    count = 0\n",
    "    if len(element['alladdedindex']) > 1:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448637"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_total_cells1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import s2sphere as s2\n",
    "import copy\n",
    "import uuid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total_cells' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-06cb8a0886ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtotal_cells\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'total_cells' is not defined"
     ]
    }
   ],
   "source": [
    "total_cells[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('collegeonly_cells_v3.json', 'r', encoding='utf8') as read_file:\n",
    "    total_cells = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_union_preserve_custom(a,b,key):\n",
    "    c = s2.CellUnion.get_union(a, b).cell_ids()\n",
    "    running_union = s2.CellUnion()\n",
    "    for cellId in copy.deepcopy(c):\n",
    "        temp_union = s2.CellUnion([cellId])\n",
    "        min_target = 10\n",
    "        if '10' in key:\n",
    "            min_target = 10\n",
    "        elif '11' in key:\n",
    "            min_target = 11\n",
    "        elif '12' in key:\n",
    "            min_target = 12\n",
    "        elif '13' in key:\n",
    "            min_target = 13\n",
    "        elif '14' in key:\n",
    "            min_target = 14\n",
    "        elif '15' in key:\n",
    "            min_target = 15\n",
    "        elif '16' in key:\n",
    "            min_target = 16\n",
    "        if cellId.level() < min_target:\n",
    "            temp_union = s2.CellUnion(temp_union.denormalize(min_target,1),raw=False)\n",
    "        running_union = s2.CellUnion.get_union(temp_union, running_union,raw=False)\n",
    "    return running_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24645"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformatForNameNew(cell_list):\n",
    "    n_dict = {}\n",
    "    intersects_g = 0\n",
    "    nointersects_g = 0\n",
    "    misfit_list = []\n",
    "    good_list = []\n",
    "    for theindex, element in enumerate(cell_list):\n",
    "        if theindex % 1000 == 0:\n",
    "            print(theindex)\n",
    "            print(intersects_g)\n",
    "            print(nointersects_g)\n",
    "            print()\n",
    "        \n",
    "        isinlist = [checkname in n_dict for checkname in element.get('allnames')]\n",
    "        if any(isinlist):\n",
    "            intersectsname = element.get('allnames')[isinlist.index(True)]\n",
    "            \n",
    "            intersects = False\n",
    "            for i in range(10, 17):\n",
    "                \n",
    "                a = s2.CellUnion(map(lambda x: s2.CellId.from_token(x), element.get('cover16s')))\n",
    "                b = s2.CellUnion(map(lambda x: s2.CellId.from_token(x), n_dict[intersectsname].get('cover16s')))\n",
    "\n",
    "                a = get_union_preserve_custom(a,a,'cover' + str(i) + 's')\n",
    "                b = get_union_preserve_custom(b,b,'cover' + str(i) + 's')\n",
    "\n",
    "\n",
    "                a.expand(i)\n",
    "                b.expand(i)\n",
    "                \n",
    "                a.normalize()\n",
    "\n",
    "                b.normalize()\n",
    "\n",
    "\n",
    "                if s2.CellUnion.get_intersection(a,b).cell_ids():\n",
    "                    intersects = True\n",
    "            if intersects:\n",
    "                \n",
    "                intersects_g += 1\n",
    "                this_el = s2.CellUnion(map(lambda x: s2.CellId.from_token(x), element.get('cover16s')))\n",
    "                dict_el = s2.CellUnion(map(lambda x: s2.CellId.from_token(x), n_dict[intersectsname].get('cover16s')))\n",
    "                new_cell_list = list(map(lambda x: x.to_token(), get_union_preserve_custom(this_el, dict_el, 'cover16s').cell_ids()))\n",
    "                n_dict[intersectsname]['cover16s'] = new_cell_list\n",
    "                \n",
    "                \n",
    "                nameset = set(element['allnames'])\n",
    "                nameset.update(n_dict[intersectsname]['allnames'])\n",
    "                \n",
    "                n_dict[intersectsname]['allnames'] = list(nameset)\n",
    "                \n",
    "                indexset = set(element['alladdedindex'])\n",
    "                indexset.update(n_dict[intersectsname]['alladdedindex'])\n",
    "                \n",
    "                n_dict[intersectsname]['alladdedindex'] = list(indexset)\n",
    "\n",
    "            else:\n",
    "                nointersects_g += 1\n",
    "                misfit_list.append(element)\n",
    "        else:\n",
    "            good_list.append(element)\n",
    "            for thisname in element.get('allnames'): \n",
    "                n_dict[thisname] = element\n",
    "\n",
    "    print(\"intersects\")\n",
    "    print(intersects_g)\n",
    "    print(\"no_intersects\")\n",
    "    print(nointersects_g)\n",
    "\n",
    "    return good_list + misfit_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "\n",
      "1000\n",
      "0\n",
      "7\n",
      "\n",
      "2000\n",
      "0\n",
      "14\n",
      "\n",
      "3000\n",
      "2\n",
      "20\n",
      "\n",
      "4000\n",
      "4\n",
      "32\n",
      "\n",
      "5000\n",
      "4\n",
      "43\n",
      "\n",
      "6000\n",
      "6\n",
      "55\n",
      "\n",
      "7000\n",
      "7\n",
      "67\n",
      "\n",
      "8000\n",
      "8\n",
      "75\n",
      "\n",
      "9000\n",
      "8\n",
      "89\n",
      "\n",
      "10000\n",
      "9\n",
      "96\n",
      "\n",
      "11000\n",
      "9\n",
      "103\n",
      "\n",
      "12000\n",
      "11\n",
      "114\n",
      "\n",
      "13000\n",
      "13\n",
      "122\n",
      "\n",
      "14000\n",
      "14\n",
      "132\n",
      "\n",
      "15000\n",
      "15\n",
      "138\n",
      "\n",
      "16000\n",
      "15\n",
      "163\n",
      "\n",
      "17000\n",
      "16\n",
      "174\n",
      "\n",
      "18000\n",
      "16\n",
      "185\n",
      "\n",
      "19000\n",
      "17\n",
      "197\n",
      "\n",
      "20000\n",
      "17\n",
      "203\n",
      "\n",
      "21000\n",
      "17\n",
      "209\n",
      "\n",
      "22000\n",
      "17\n",
      "215\n",
      "\n",
      "23000\n",
      "17\n",
      "221\n",
      "\n",
      "24000\n",
      "99\n",
      "789\n",
      "\n",
      "intersects\n",
      "180\n",
      "no_intersects\n",
      "1348\n"
     ]
    }
   ],
   "source": [
    "total_cells1 = reformatForNameNew(total_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('collegeonly_v4.json', 'w', encoding='utf8') as write_file:\n",
    "    json.dump(total_cells1, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in total_cells1:\n",
    "    if 'University of California, Berkeley' in element.get('allnames'):\n",
    "        [print(el + ',') for el in element.get('cover16s')]\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [print(el + ',') for el in list(map(lambda x: x.to_token(), s2.CellUnion(g.get_edge_neighbors(), raw=False).cell_ids()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################@@@@@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import s2sphere as s2\n",
    "import copy\n",
    "import uuid\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = logging.getLogger()\n",
    "lg.handlers = [] # This is the key thing for the question!\n",
    "\n",
    "# Start defining and assigning your handlers here\n",
    "handler = logging.StreamHandler()\n",
    "handler.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter(\"%(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "lg.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('newusindex8.json', 'r', encoding='utf8') as read_file:\n",
    "    total_cells = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6780"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reformatToGeoJson(boundaries):\n",
    "#     geojson = {\n",
    "#       \"type\": \"FeatureCollection\"\n",
    "#     }\n",
    "    \n",
    "#     geojson[\"features\"] = []\n",
    "    \n",
    "#     for bindex,boundary in enumerate(boundaries):\n",
    "        \n",
    "#         newdict = {}\n",
    "#         newdict[\"type\"] = \"Feature\"\n",
    "#         newdict[\"properties\"] = {}\n",
    "#         newdict[\"geometry\"] = {}\n",
    "#         newdict[\"geometry\"][\"type\"] = \"Polygon\"\n",
    "#         newdict[\"geometry\"][\"coordinates\"] = [[]]\n",
    "        \n",
    "#         for theindex, thetuple in enumerate(boundary):\n",
    "#             newdict[\"geometry\"][\"coordinates\"][0].append(list(thetuple))\n",
    "        \n",
    "#         geojson[\"features\"].append(newdict)\n",
    "    \n",
    "\n",
    "#     return geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_all_boundary(parent_cell_union_list, level=16):\n",
    "    \n",
    "#     def find_islands(cell_union_list, level):\n",
    "                \n",
    "#         tight_union = s2.CellUnion(list(map(lambda x: s2.CellId.from_token(x), cell_union_list))).denormalize(level,1)\n",
    "\n",
    "#         assert len(tight_union) > 0\n",
    "    \n",
    "#         all_islands = []\n",
    "        \n",
    "#         all_cells = set(map(lambda x: x.to_token(), tight_union[:]))\n",
    "    \n",
    "        \n",
    "#         while all_cells:\n",
    "#             all_cells_copy = all_cells.copy()\n",
    "            \n",
    "#             start = all_cells_copy.pop()\n",
    "#             frontier = set([start])\n",
    "#             all_nbrs = set([start])\n",
    "            \n",
    "#             while frontier:\n",
    "#                 cell_id = frontier.pop()\n",
    "#                 neighbors = list(map(lambda x: x.to_token(), s2.CellId.from_token(cell_id).get_all_neighbors(level)))\n",
    "#                 for nbr in neighbors:\n",
    "#                     if nbr in all_cells:\n",
    "#                         if nbr in all_cells_copy and nbr not in frontier:\n",
    "#                             frontier.add(nbr)\n",
    "#                             all_cells_copy.remove(nbr)\n",
    "#                             all_nbrs.add(nbr)\n",
    "\n",
    "#             all_islands.append(list(all_nbrs))\n",
    "            \n",
    "#             for nbr in all_islands[-1]:\n",
    "#                 all_cells.remove(nbr)\n",
    "            \n",
    "#         return all_islands\n",
    "        \n",
    "#     def findOuterBoundary(cell_union_island_list, level):\n",
    "        \n",
    "#         def algo(x):\n",
    "#             return (math.atan2(x[0] - mlat, x[1] - mlng) + 2 * math.pi) % (2*math.pi)\n",
    "\n",
    "#         def dist(x,y):\n",
    "#             return math.hypot(y[0]-x[0],y[1]-x[1])\n",
    "\n",
    "#         tight_union = s2.CellUnion(list(map(lambda x: s2.CellId.from_token(x), cell_union_island_list)))\n",
    "\n",
    "#         tight_union_expanded = s2.CellUnion(list(map(lambda x: s2.CellId.from_token(x), cell_union_island_list)))\n",
    "#         tight_union_expanded.expand(level)\n",
    "\n",
    "#         tight_union_bound = tight_union.get_rect_bound()\n",
    "\n",
    "#         topleft = s2.CellId.from_lat_lng(s2.LatLng.from_degrees(tight_union_bound.lat_hi().degrees, tight_union_bound.lng_lo().degrees)).parent(level)\n",
    "#         topleftneighborbox = s2.CellUnion(list(topleft.get_all_neighbors(level)),raw=False).get_rect_bound()\n",
    "\n",
    "\n",
    "#         topleft2 = s2.CellId.from_lat_lng(s2.LatLng.from_degrees(topleftneighborbox.lat_hi().degrees, topleftneighborbox.lng_lo().degrees)).parent(level)\n",
    "\n",
    "\n",
    "#         bottomright = s2.CellId.from_lat_lng(s2.LatLng.from_degrees(tight_union_bound.lat_lo().degrees, tight_union_bound.lng_hi().degrees)).parent(level)\n",
    "#         bottomrightneighborbox = s2.CellUnion(list(bottomright.get_all_neighbors(level)),raw=False).get_rect_bound()\n",
    "\n",
    "#         bottomright2 = s2.CellId.from_lat_lng(s2.LatLng.from_degrees(bottomrightneighborbox.lat_lo().degrees, bottomrightneighborbox.lng_hi().degrees)).parent(level)\n",
    "\n",
    "\n",
    "\n",
    "#         topleftpoint = s2.LatLng.from_degrees(s2.CellUnion([topleft2]).get_rect_bound().lat_hi().degrees, s2.CellUnion([topleft2]).get_rect_bound().lng_lo().degrees)\n",
    "#         bottomrightpoint = s2.LatLng.from_degrees(s2.CellUnion([bottomright2]).get_rect_bound().lat_lo().degrees, s2.CellUnion([bottomright2]).get_rect_bound().lng_hi().degrees)\n",
    "\n",
    "\n",
    "#         outerbound = s2.LatLngRect.from_point_pair(topleftpoint,bottomrightpoint)\n",
    "\n",
    "#         rc = s2.RegionCoverer()\n",
    "\n",
    "#         rc.max_level = level\n",
    "#         rc.min_level = level\n",
    "#         rc.level_mod = 1\n",
    "\n",
    "\n",
    "#         outercovering = s2.CellUnion(list(rc.get_simple_reverse_covering(outerbound, tight_union, topleft2.to_point(), level)))\n",
    "\n",
    "#         outercoveringexpanded = s2.CellUnion(list(rc.get_simple_reverse_covering(outerbound, tight_union, topleft2.to_point(), level)))\n",
    "\n",
    "#         outercoveringexpanded.expand(level)\n",
    "\n",
    "\n",
    "#         outercoveringexpanded.normalize()\n",
    "\n",
    "#         outercovering.normalize()\n",
    "\n",
    "#         tight_union_expanded.normalize()\n",
    "\n",
    "#         tight_union.normalize()\n",
    "\n",
    "\n",
    "#         finalintersectioninner = list(s2.CellUnion.get_intersection( outercoveringexpanded,tight_union).denormalize(level, 1))\n",
    "\n",
    "#         finalintersectionouter = list(s2.CellUnion.get_intersection( outercovering,tight_union_expanded).denormalize(level, 1))\n",
    "\n",
    "\n",
    "#         def all_possible_coordinates(forcoordinate_cellid_list):\n",
    "#             thiscoordinateset = set()\n",
    "            \n",
    "# #             edges = set()\n",
    "# #             diagonals = set()\n",
    "            \n",
    "#             for thiscellid in forcoordinate_cellid_list:\n",
    "                \n",
    "# #                 thiscelledges = set()\n",
    "# #                 thiscelldiagonals = set()\n",
    "                \n",
    "#                 cellrep = s2.Cell(thiscellid)\n",
    "                \n",
    "#                 s2v0 = s2.LatLng.from_point(cellrep.get_vertex(0))\n",
    "#                 s2v1 = s2.LatLng.from_point(cellrep.get_vertex(1))\n",
    "#                 s2v2 = s2.LatLng.from_point(cellrep.get_vertex(2))\n",
    "#                 s2v3 = s2.LatLng.from_point(cellrep.get_vertex(3))\n",
    "                \n",
    "#                 v0 = (s2v0.lat().degrees, s2v0.lng().degrees)\n",
    "#                 v1 = (s2v1.lat().degrees, s2v1.lng().degrees)\n",
    "#                 v2 = (s2v2.lat().degrees, s2v2.lng().degrees)\n",
    "#                 v3 = (s2v3.lat().degrees, s2v3.lng().degrees)\n",
    "                \n",
    "#                 thiscoordinateset.update([v0,v1,v2,v3])\n",
    "                \n",
    "# #                 edges.update([(v0,v1), (v1,v0), (v0,v3), (v3,v0), (v1,v2), (v2,v1), (v2, v3), (v3, v2)])\n",
    "                \n",
    "# #                 diagonals.update([(v0,v2), (v2,v0), (v1,v3), (v3,v1)])\n",
    "                \n",
    "#             return thiscoordinateset\n",
    "# #             return thiscoordinateset, edges, diagonals\n",
    "\n",
    "\n",
    "        \n",
    "#         outercoordinateset = all_possible_coordinates(finalintersectionouter)\n",
    "        \n",
    "#         innercoordinateset = all_possible_coordinates(finalintersectioninner)\n",
    "# #         outercoordinateset, outeredges, outerdiagonals = all_possible_coordinates(finalintersectionouter)\n",
    "\n",
    "# #         innercoordinateset, inneredges, innerdiagonals = all_possible_coordinates(finalintersectioninner)\n",
    "\n",
    "#         finalcoordinatelist = list(innercoordinateset.intersection(outercoordinateset))\n",
    "\n",
    "# #         combinededges = inneredges\n",
    "# #         combineddiagonals = innerdiagonals\n",
    "        \n",
    "#         mlat = float(sum(x[0] for x in finalcoordinatelist)) / max(len(finalcoordinatelist), 1)\n",
    "#         mlng = float(sum(x[1] for x in finalcoordinatelist)) / max(len(finalcoordinatelist), 1)\n",
    "        \n",
    "#         finalcoordinatelist.sort(key=algo)\n",
    "        \n",
    "    \n",
    "# #         def undodiagonalmovements(combinededges, combineddiagonals, path):\n",
    "            \n",
    "# #             seencoords = set()\n",
    "# #             frontier = [path[0]]\n",
    "            \n",
    "# # #             lg.warning(len(path))\n",
    "            \n",
    "# #             while frontier:\n",
    "# #                 thepoint = frontier.pop()\n",
    "# #                 indexofthepoint = path.index(thepoint)\n",
    "# #                 if thepoint not in seencoords:\n",
    "# #                     seencoords.add(thepoint)\n",
    "# #                     reptuple = (thepoint, path[(indexofthepoint + 1) % len(path)])\n",
    "\n",
    "# # #                     lg.warning(reptuple)\n",
    "\n",
    "# #                     isdiagonal = False\n",
    "# # #                     for diagonalset in combineddiagonals:\n",
    "# #                     if reptuple in combineddiagonals:\n",
    "# #                         isdiagonal = True\n",
    "# # #                     lg.warning(isdiagonal)\n",
    "\n",
    "# #                     if isdiagonal:\n",
    "# #                         path[(indexofthepoint + 1) % len(path)], path[(indexofthepoint + 2) % len(path)] = path[(indexofthepoint + 2) % len(path)], path[(indexofthepoint + 1) % len(path)]\n",
    "# #                     frontier.append(path[(indexofthepoint + 1) % len(path)])\n",
    "# # #             lg.warning('\\n')\n",
    "# #             return path\n",
    "            \n",
    "        \n",
    "        \n",
    "#         originalpath = deepcopy(finalcoordinatelist)\n",
    "        \n",
    "# #         originalpath = undodiagonalmovements(combinededges, combineddiagonals, deepcopy(finalcoordinatelist))\n",
    "        \n",
    "        \n",
    "#         if originalpath[0] != originalpath[-1]:\n",
    "#             originalpath.append(originalpath[0])\n",
    "        \n",
    "#         originalcentroid = deepcopy((mlat, mlng))\n",
    "        \n",
    "#         for shiftindex in range(5):\n",
    "                        \n",
    "#             mlat = float(sum(x[0] for x in finalcoordinatelist)) / max(len(finalcoordinatelist), 1)\n",
    "#             mlng = float(sum(x[1] for x in finalcoordinatelist)) / max(len(finalcoordinatelist), 1)\n",
    "            \n",
    "#             frontier = [finalcoordinatelist[shiftindex]]\n",
    "#             newpath = [finalcoordinatelist[shiftindex]]\n",
    "#             seencoords = set([finalcoordinatelist[shiftindex]])\n",
    "#             while frontier:\n",
    "#                 thepoint = frontier.pop()\n",
    "#                 indexofthepoint = finalcoordinatelist.index(thepoint)\n",
    "\n",
    "                \n",
    "#                 horizon = 2\n",
    "\n",
    "#                 horizonlist = []\n",
    "#                 for horizonindex in range(1, horizon + 1):\n",
    "#                     horizonpoint = finalcoordinatelist[(indexofthepoint + horizonindex) % len(finalcoordinatelist)]\n",
    "#                     wrappedlastindex = ((indexofthepoint - 1) + len(finalcoordinatelist)) % (len(finalcoordinatelist))\n",
    "                    \n",
    "#                     if horizonpoint != finalcoordinatelist[indexofthepoint] or horizonpoint != finalcoordinatelist[wrappedlastindex]:\n",
    "#                         horizonlist.append((dist(thepoint,horizonpoint), horizonpoint))\n",
    "\n",
    "#                 thedist, closestpoint = min(horizonlist, key = lambda x: x[0])\n",
    "\n",
    "#                 if closestpoint not in seencoords:\n",
    "#                     frontier.append(closestpoint)\n",
    "#                     newpath.append(closestpoint)\n",
    "#                     seencoords.add(closestpoint)\n",
    "                    \n",
    "#             finalcoordinatelist = deepcopy(newpath)\n",
    "            \n",
    "#         flat = float(sum(x[0] for x in finalcoordinatelist)) / max(len(finalcoordinatelist), 1)\n",
    "#         flng = float(sum(x[1] for x in finalcoordinatelist)) / max(len(finalcoordinatelist), 1)\n",
    "        \n",
    "#         finalcentroid = (flat, flng)\n",
    "        \n",
    "#         if not finalcoordinatelist[-1] == finalcoordinatelist[0]:\n",
    "#             finalcoordinatelist.append(finalcoordinatelist[0])\n",
    "\n",
    "#         return finalintersectioninner, finalintersectionouter, originalpath, originalcentroid, finalcoordinatelist, finalcentroid\n",
    "#         #return finalcoordinatelist + [finalcoordinatelist[0]]\n",
    "\n",
    "#     islandreturnlist = []\n",
    "    \n",
    "#     def reformatToSingleBoundaryOSM(boundary):\n",
    "#         thestr = ''\n",
    "#         thestr += '(('\n",
    "#         for thetuple in boundary:\n",
    "#             thestr += str(thetuple[1]) + ' ' + str(thetuple[0]) + ','\n",
    "#         thestr = thestr[:-1]\n",
    "#         thestr += ')),'\n",
    "#         thestr = thestr[:-1]\n",
    "#         return \"MULTIPOLYGON(\" + thestr + \")\"\n",
    "    \n",
    "#     for island in find_islands(parent_cell_union_list, level):\n",
    "#         cellboundaryinner, cellboundaryouter, originalpath, originalcentroid, finalpath, finalcentroid = findOuterBoundary(island, level)\n",
    "        \n",
    "#         osmooriginalpath = reformatToSingleBoundaryOSM(originalpath)\n",
    "#         osmfinalpath = reformatToSingleBoundaryOSM(finalpath)\n",
    "        \n",
    "#         newdict = {}\n",
    "        \n",
    "#         newdict[\"island\"] = island\n",
    "#         newdict[\"cellboundaryinner\"] = list(map(lambda x: x.to_token(), cellboundaryinner))\n",
    "#         newdict[\"cellboundaryouter\"] = list(map(lambda x: x.to_token(), cellboundaryouter))\n",
    "#         newdict[\"originalpath\"] = originalpath\n",
    "#         newdict[\"originalcentroid\"] = originalcentroid\n",
    "#         newdict[\"osmooriginalpath\"] = osmooriginalpath\n",
    "#         newdict[\"finalpath\"] = finalpath\n",
    "#         newdict[\"finalcentroid\"] = finalcentroid\n",
    "#         newdict[\"osmfinalpath\"] = osmfinalpath\n",
    "        \n",
    "#         islandreturnlist.append(newdict)\n",
    "        \n",
    "#     return islandreturnlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s2sphere as s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/s2sphere']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2.__path__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_boundary(parent_cell_union_list, level=16):\n",
    "\n",
    "    def find_islands(cell_union_list, level):\n",
    "\n",
    "        tight_union = s2.CellUnion(list(map(lambda x: s2.CellId.from_token(x), cell_union_list))).denormalize(level,1)\n",
    "\n",
    "        assert len(tight_union) > 0\n",
    "\n",
    "        all_islands = []\n",
    "\n",
    "        all_cells = set(map(lambda x: x.to_token(), tight_union[:]))\n",
    "\n",
    "\n",
    "        while all_cells:\n",
    "            all_cells_copy = all_cells.copy()\n",
    "\n",
    "            start = all_cells_copy.pop()\n",
    "            frontier = set([start])\n",
    "            all_nbrs = set([start])\n",
    "\n",
    "            while frontier:\n",
    "                cell_id = frontier.pop()\n",
    "                neighbors = list(map(lambda x: x.to_token(), s2.CellId.from_token(cell_id).get_edge_neighbors()))\n",
    "                for nbr in neighbors:\n",
    "                    if nbr in all_cells:\n",
    "                        if nbr in all_cells_copy and nbr not in frontier:\n",
    "                            frontier.add(nbr)\n",
    "                            all_cells_copy.remove(nbr)\n",
    "                            all_nbrs.add(nbr)\n",
    "\n",
    "            all_islands.append(list(all_nbrs))\n",
    "\n",
    "            for nbr in all_islands[-1]:\n",
    "                all_cells.remove(nbr)\n",
    "\n",
    "        return all_islands\n",
    "\n",
    "    def findOuterBoundary(cell_union_island_list, level):\n",
    "\n",
    "        def dist(x,y):\n",
    "            return math.hypot(y[0]-x[0],y[1]-x[1])\n",
    "\n",
    "        tight_union = s2.CellUnion(list(map(lambda x: s2.CellId.from_token(x), cell_union_island_list)))\n",
    "\n",
    "        tight_union_expanded = s2.CellUnion(list(map(lambda x: s2.CellId.from_token(x), cell_union_island_list)))\n",
    "        tight_union_expanded.expand(level)\n",
    "\n",
    "        tight_union_bound = tight_union.get_rect_bound()\n",
    "\n",
    "        topleft = s2.CellId.from_lat_lng(s2.LatLng.from_degrees(tight_union_bound.lat_hi().degrees, tight_union_bound.lng_lo().degrees)).parent(level)\n",
    "        topleftneighborbox = s2.CellUnion(list(topleft.get_all_neighbors(level)),raw=False).get_rect_bound()\n",
    "\n",
    "\n",
    "        topleft2 = s2.CellId.from_lat_lng(s2.LatLng.from_degrees(topleftneighborbox.lat_hi().degrees, topleftneighborbox.lng_lo().degrees)).parent(level)\n",
    "\n",
    "\n",
    "        bottomright = s2.CellId.from_lat_lng(s2.LatLng.from_degrees(tight_union_bound.lat_lo().degrees, tight_union_bound.lng_hi().degrees)).parent(level)\n",
    "        bottomrightneighborbox = s2.CellUnion(list(bottomright.get_all_neighbors(level)),raw=False).get_rect_bound()\n",
    "\n",
    "        bottomright2 = s2.CellId.from_lat_lng(s2.LatLng.from_degrees(bottomrightneighborbox.lat_lo().degrees, bottomrightneighborbox.lng_hi().degrees)).parent(level)\n",
    "\n",
    "\n",
    "\n",
    "        topleftpoint = s2.LatLng.from_degrees(s2.CellUnion([topleft2]).get_rect_bound().lat_hi().degrees, s2.CellUnion([topleft2]).get_rect_bound().lng_lo().degrees)\n",
    "        bottomrightpoint = s2.LatLng.from_degrees(s2.CellUnion([bottomright2]).get_rect_bound().lat_lo().degrees, s2.CellUnion([bottomright2]).get_rect_bound().lng_hi().degrees)\n",
    "\n",
    "\n",
    "        outerbound = s2.LatLngRect.from_point_pair(topleftpoint,bottomrightpoint)\n",
    "\n",
    "        rc = s2.RegionCoverer()\n",
    "\n",
    "        rc.max_level = level\n",
    "        rc.min_level = level\n",
    "        rc.level_mod = 1\n",
    "\n",
    "\n",
    "        outercovering = s2.CellUnion(list(rc.get_simple_reverse_covering(outerbound, tight_union, topleft2.to_point(), level)))\n",
    "\n",
    "        outercoveringexpanded = s2.CellUnion(list(rc.get_simple_reverse_covering(outerbound, tight_union, topleft2.to_point(), level)))\n",
    "\n",
    "        outercoveringexpanded.expand(level)\n",
    "\n",
    "\n",
    "        outercoveringexpanded.normalize()\n",
    "\n",
    "        outercovering.normalize()\n",
    "\n",
    "        tight_union_expanded.normalize()\n",
    "\n",
    "        tight_union.normalize()\n",
    "\n",
    "\n",
    "        finalintersectioninner = list(s2.CellUnion.get_intersection( outercoveringexpanded,tight_union).denormalize(level, 1))\n",
    "\n",
    "        finalintersectionouter = list(s2.CellUnion.get_intersection( outercovering,tight_union_expanded).denormalize(level, 1))\n",
    "\n",
    "        innertokens = set(list(map(lambda x: x.to_token(), finalintersectioninner)))\n",
    "        outertokens = set(list(map(lambda x: x.to_token(), finalintersectionouter)))\n",
    "\n",
    "\n",
    "        def checkccw(points):\n",
    "            doubleArea = 0\n",
    "            for indexp, point in enumerate(points):\n",
    "                x1 = point[0]\n",
    "                y1 = point[1]\n",
    "                x2 = points[(indexp + 1) % len(points)][0]\n",
    "                y2 = points[(indexp + 1) % len(points)][1]\n",
    "                doubleArea += (x2 - x1) * (y2 + y1)\n",
    "            return doubleArea\n",
    "\n",
    "        def edgeconnections(forcoordinate_cellid_list, ccw=True, double=False):\n",
    "\n",
    "            def algo(x):\n",
    "                return (math.atan2(x[0] - mlat, x[1] - mlng) + 2 * math.pi) % (2*math.pi)\n",
    "\n",
    "            edgeset = set()\n",
    "\n",
    "            for thiscellid in forcoordinate_cellid_list:\n",
    "\n",
    "                cellrep = s2.Cell(thiscellid)\n",
    "\n",
    "                s2v0 = s2.LatLng.from_point(cellrep.get_vertex(0))\n",
    "                s2v1 = s2.LatLng.from_point(cellrep.get_vertex(1))\n",
    "                s2v2 = s2.LatLng.from_point(cellrep.get_vertex(2))\n",
    "                s2v3 = s2.LatLng.from_point(cellrep.get_vertex(3))\n",
    "\n",
    "                v0 = (s2v0.lat().degrees, s2v0.lng().degrees)\n",
    "                v1 = (s2v1.lat().degrees, s2v1.lng().degrees)\n",
    "                v2 = (s2v2.lat().degrees, s2v2.lng().degrees)\n",
    "                v3 = (s2v3.lat().degrees, s2v3.lng().degrees)\n",
    "\n",
    "                s2center = s2.LatLng.from_point(cellrep.get_center())\n",
    "\n",
    "                mlat = s2center.lat().degrees\n",
    "                mlng = s2center.lng().degrees\n",
    "\n",
    "                edgeset.add((v0, v1))\n",
    "                edgeset.add((v1, v0))\n",
    "\n",
    "                edgeset.add((v0, v3))\n",
    "                edgeset.add((v3, v0))\n",
    "\n",
    "                edgeset.add((v1, v2))\n",
    "                edgeset.add((v2, v1))\n",
    "\n",
    "                edgeset.add((v3, v2))\n",
    "                edgeset.add((v2, v3))\n",
    "\n",
    "            return edgeset\n",
    "\n",
    "\n",
    "        a = edgeconnections(finalintersectioninner,double=True,ccw=False)\n",
    "        b = edgeconnections(finalintersectionouter,double=True,ccw=True)\n",
    "\n",
    "\n",
    "        boundingedgeset = a.intersection(b)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        specificedge = boundingedgeset.pop()\n",
    "        finalpath = [specificedge[0]]\n",
    "        seencoords = set([specificedge[0]])\n",
    "        boundingedgeset.add(specificedge)\n",
    "        fresh = True\n",
    "\n",
    "        edgecoorddict = {}\n",
    "        for ttedge in boundingedgeset:\n",
    "            if (ttedge[0][0], ttedge[0][1]) in edgecoorddict:\n",
    "                edgecoorddict[(ttedge[0][0], ttedge[0][1])].add(ttedge)\n",
    "            else:\n",
    "                edgecoorddict[(ttedge[0][0], ttedge[0][1])] = set([ttedge])\n",
    "            if (ttedge[1][0], ttedge[1][1]) in edgecoorddict:\n",
    "                edgecoorddict[(ttedge[1][0], ttedge[1][1])].add(ttedge)\n",
    "            else:\n",
    "                edgecoorddict[(ttedge[1][0], ttedge[1][1])] = set([ttedge])\n",
    "\n",
    "\n",
    "        while finalpath[0] != specificedge[0] or fresh:\n",
    "            fresh = False\n",
    "\n",
    "            boundingedgeset.remove(specificedge)\n",
    "\n",
    "            #start of edge\n",
    "            if specificedge[0] not in seencoords:\n",
    "                finalpath.append(specificedge[0])\n",
    "                seencoords.add(specificedge[0])\n",
    "\n",
    "            coorspcoordset = edgecoorddict[(specificedge[1][0],specificedge[1][1])]\n",
    "\n",
    "            copyset = coorspcoordset.copy()\n",
    "\n",
    "            copyset.discard(specificedge)\n",
    "\n",
    "            copyset.discard((specificedge[1], specificedge[0]))\n",
    "\n",
    "            if len(copyset) == 1:\n",
    "                specificedge = copyset.pop()\n",
    "            elif len(copyset) == 2:\n",
    "                cand1, cand2 = copyset.pop(), copyset.pop()\n",
    "                if not cand1[1] == specificedge[1]:\n",
    "                    specificedge = cand1\n",
    "                elif not cand2[1] == specificedge[1]:\n",
    "                    specificedge = cand2\n",
    "\n",
    "\n",
    "        actualfinalpath = finalpath + [finalpath[0]]\n",
    "        ccwarea = checkccw(actualfinalpath)\n",
    "\n",
    "\n",
    "        if ccwarea <= 0:\n",
    "            return finalintersectioninner, finalintersectionouter, actualfinalpath\n",
    "        else:\n",
    "            return finalintersectioninner, finalintersectionouter, actualfinalpath[::-1]\n",
    "\n",
    "    def reformatToSingleBoundaryOSM(boundary):\n",
    "        thestr = ''\n",
    "        thestr += '(('\n",
    "        for thetuple in boundary:\n",
    "            thestr += str(thetuple[1]) + ' ' + str(thetuple[0]) + ','\n",
    "        thestr = thestr[:-1]\n",
    "        thestr += ')),'\n",
    "        thestr = thestr[:-1]\n",
    "        return \"MULTIPOLYGON(\" + thestr + \")\"\n",
    "\n",
    "    islandreturnlist = []\n",
    "\n",
    "    for island in find_islands(parent_cell_union_list, level):\n",
    "        cellboundaryinner, cellboundaryouter, ccwpath = findOuterBoundary(island, level)\n",
    "\n",
    "        osmccwpath = reformatToSingleBoundaryOSM(ccwpath)\n",
    "\n",
    "\n",
    "        newdict = {}\n",
    "\n",
    "        newdict[\"island\"] = island\n",
    "        newdict[\"cellboundaryinner\"] = list(map(lambda x: x.to_token(), cellboundaryinner))\n",
    "        newdict[\"cellboundaryouter\"] = list(map(lambda x: x.to_token(), cellboundaryouter))\n",
    "        newdict[\"ccwpath\"] = ccwpath\n",
    "        newdict[\"osmccwpath\"] = osmccwpath\n",
    "\n",
    "        islandreturnlist.append(newdict)\n",
    "\n",
    "    return islandreturnlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addBoundariesToList(dataset_list):\n",
    "    copy_dataset_list = deepcopy(dataset_list)\n",
    "\n",
    "    def reformatToOSM(boundaries):\n",
    "        thestr = ''\n",
    "\n",
    "        for boundary in boundaries:\n",
    "            thestr += '(('\n",
    "            for thetuple in boundary:\n",
    "                thestr += str(thetuple[1]) + ' ' + str(thetuple[0]) + ','\n",
    "            thestr = thestr[:-1]\n",
    "            thestr += ')),'\n",
    "        thestr = thestr[:-1]\n",
    "        return \"MULTIPOLYGON(\" + thestr + \")\"\n",
    "    \n",
    "    \n",
    "    for itemindex, item in enumerate(copy_dataset_list):\n",
    "        if itemindex % 1000 == 0:\n",
    "            print(itemindex)\n",
    "        if item.get('cover16s'):\n",
    "            item[\"islands\"] = find_all_boundary(item.get('cover16s'))\n",
    "            completeoutercellboundary = set()\n",
    "            completeinnercellboundary = set()\n",
    "            completeccwpolygon = []     \n",
    "\n",
    "            for island in item[\"islands\"]: \n",
    "\n",
    "                completeoutercellboundary.update(island[\"cellboundaryouter\"])\n",
    "                completeinnercellboundary.update(island[\"cellboundaryinner\"])\n",
    "\n",
    "                completeccwpolygon.append(island[\"ccwpath\"])\n",
    "\n",
    "            newdict = {}\n",
    "\n",
    "            osmcompleteccwpath = reformatToOSM(completeccwpolygon)\n",
    "\n",
    "            newdict[\"ccwpath\"] = completeccwpolygon\n",
    "\n",
    "            newdict[\"cellboundaryinner\"] = list(completeinnercellboundary)\n",
    "            newdict[\"cellboundaryouter\"] = list(completeoutercellboundary)\n",
    "\n",
    "            newdict[\"osmccwpath\"] = osmcompleteccwpath\n",
    "\n",
    "            item[\"combinedislands\"] = newdict\n",
    "    return copy_dataset_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6780\n"
     ]
    }
   ],
   "source": [
    "print(len(total_cells))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n"
     ]
    }
   ],
   "source": [
    "splicelist = addBoundariesToList(total_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(splicelist[0][\"combinedislands\"]['osmccwpath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('newusindex9pretty.json', 'w', encoding='utf8') as write_file:\n",
    "    json.dump(splicelist, write_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splicelist[0][\"cover16s\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _= [print(el + ',') for el in splicelist[0][\"islands\"][1]['cellboundaryouter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splicelist[0].get('cover16s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(37.87447067704782, -122.22142497201747), (37.87566184724264, -122.22142497201747), (37.876419734256686, -122.22284344012643), (37.87685299766635, -122.22142497201747), (37.87717757598074, -122.22426188942785), (37.87761086033473, -122.22284344012643), (37.877935372416076, -122.22568031991976), (37.878368677713325, -122.22426188942785), (37.879126449803444, -122.22568031991976), (37.87988417660635, -122.22709873160005), (37.88031750741823, -122.22568031991976), (37.881075209875995, -122.22709873160005), (37.88064185812336, -122.22851712446668), (37.88183286704808, -122.22851712446668), (37.881399494355755, -122.2299354985176), (37.882590478935775, -122.2299354985176), (37.882157085304826, -122.23135385375079), (37.881723675307256, -122.23277219016417), (37.88291463097187, -122.23277219016417), (37.88248120003743, -122.23419050775568), (37.882047752738174, -122.23560880652335), (37.88323867948791, -122.23560880652335), (37.884429586465, -122.23560880652335), (37.88399611366001, -122.237027086465), (37.883562624491596, -122.23844534757872), (37.88475350255502, -122.23844534757872), (37.88594436084548, -122.23844534757872), (37.88551084617421, -122.23986358986237), (37.883886465990585, -122.24128181331392), (37.88507731514089, -122.24128181331392), (37.88345292316707, -122.24270001793133), (37.88301936398419, -122.24411820371257), (37.884210203992566, -122.24411820371257), (37.88377662387983, -122.24553637065554), (37.882152196544894, -122.24695451875826), (37.88334302740955, -122.24695451875826), (37.881718588290724, -122.24837264801866), (37.88128496368172, -122.24979075843467), (37.88204213986478, -122.25120885000425), (37.88085132271903, -122.25120885000425), (37.88160847797565, -122.25262692272538), (37.881174799734644, -122.25404497659599), (37.88074110514288, -122.25546301161404), (37.87955030172006, -122.25546301161404), (37.87835947853416, -122.25546301161404), (37.879116595353864, -122.25688102777748), (37.878682872639644, -122.25829902508427), (37.87792577674399, -122.25688102777748), (37.87716863558618, -122.25546301161404), (37.87824913357851, -122.25971700353236), (37.87857238696243, -122.26255290384427), (37.87673493837286, -122.25688102777748), (37.87781537817159, -122.2611349631197), (37.87813859428994, -122.26397082570398), (37.877381606420045, -122.26255290384427), (37.877704785274624, -122.26538872869685), (37.87727095991762, -122.26680661282077), (37.87683711822005, -122.26822447807373), (37.87564635599003, -122.26822447807373), (37.87445557400437, -122.26822447807373), (37.874021725126624, -122.26964232445368), (37.87358785991147, -122.27106015195858), (37.87315397836003, -122.27247796058637), (37.87196319036363, -122.27247796058637), (37.87207395077008, -122.26822447807373), (37.87164011105486, -122.26964232445368), (37.87120625500314, -122.27106015195858), (37.87077238261603, -122.27247796058637), (37.870883109523405, -122.26822447807373), (37.870126062737626, -122.26680661282077), (37.869692248525, -122.26822447807373), (37.86893517740478, -122.26680661282077), (37.86850136777587, -122.26822447807373), (37.86731046727699, -122.26822447807373), (37.86774427232135, -122.26680661282077), (37.86655334748831, -122.26680661282077), (37.86698713161077, -122.26538872869685), (37.86742089939554, -122.263970825704), (37.867854650841494, -122.26255290384427), (37.865796182443376, -122.26538872869685), (37.86622994564285, -122.263970825704), (37.86666369250395, -122.26255290384427), (37.86709742302555, -122.2611349631197), (37.865906440352646, -122.2611349631197), (37.86471543792978, -122.2611349631197), (37.86352441575795, -122.2611349631197), (37.86558283161004, -122.25829902508427), (37.86395811618207, -122.25971700353236), (37.86601650393772, -122.25688102777748), (37.864391800265764, -122.25829902508427), (37.8648254680079, -122.25688102777748), (37.86363441232759, -122.25688102777748), (37.86850845278725, -122.25262692272538), (37.8640680591411, -122.25546301161404), (37.86569275446295, -122.25404497659599), (37.86731742285739, -122.25262692272538), (37.86450168961124, -122.25404497659599), (37.86894206431852, -122.25120885000425), (37.8661263731736, -122.25262692272538), (37.869375659501664, -122.24979075843467), (37.86980923833558, -122.24837264801866), (37.86905175256016, -122.24695451875826), (37.870242800819106, -122.24695451875826), (37.868294221512855, -122.24553637065554), (37.86948529411102, -122.24553637065557), (37.868727742129984, -122.24411820371257), (37.86916124639423, -122.24270001793133), (37.86959473430445, -122.24128181331392), (37.86883709517751, -122.23986358986237), (37.86927054579574, -122.23844534757872), (37.87002820585954, -122.23986358986237), (37.86894625377587, -122.23560880652335), (37.869703980057, -122.237027086465), (37.86937965073974, -122.23419050775568), (37.87013739796017, -122.23560880652335), (37.8698130313437, -122.23277219016417), (37.87024639558662, -122.23135385375079), (37.87067974346736, -122.2299354985176), (37.87111307498481, -122.22851712446668), (37.871546390137816, -122.22709873160005), (37.87273756179585, -122.22709873160005), (37.87317086516069, -122.22568031991976), (37.87360415215838, -122.22426188942785), (37.8740374227878, -122.22284344012643), (37.87447067704782, -122.22142497201747)]\n"
     ]
    }
   ],
   "source": [
    "print(splicelist[0][\"islands\"][1]['originalpath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yo = find_all_boundary(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(reformatToOSM(yo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(json.dumps(reformatToGeoJson(yo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = s2.CellId.from_token('3b00c5875')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = s2.LatLng.from_point(s2.Cell(aa).get_vertex(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pp.to_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.CellId.from_lat_lng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.918144396037375,78.1108279156293\n"
     ]
    }
   ],
   "source": [
    "print(str(pp.lat().degrees) + ',' + str(pp.lng().degrees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alledgesanddiagonals(cell_list):\n",
    "    \n",
    "    def toUsableLatLng(s2p):\n",
    "        latlngp = s2.LatLng.from_point(s2p)\n",
    "        p = (latlngp.lat().degrees, latlngp.lng().degrees)\n",
    "        return p\n",
    "\n",
    "    def toS2pt(atuple):\n",
    "        return s2.LatLng.from_degrees(atuple[0], atuple[1]).to_point()\n",
    "    \n",
    "    def midpointSet(p1, p2):  \n",
    "        marginalerror = 0.00000001\n",
    "        themidtuple = ((p1[0]+p2[0])/2, (p1[1]+p2[1])/2)\n",
    "        v1 = (themidtuple[0] + marginalerror, themidtuple[1])\n",
    "        v2 = (themidtuple[0] - marginalerror, themidtuple[1])\n",
    "        v3 = (themidtuple[0], themidtuple[1] - marginalerror)\n",
    "        v4 = (themidtuple[0], themidtuple[1] + marginalerror)\n",
    "        return [v1, v2, v3, v4]\n",
    "\n",
    "    edges = set()\n",
    "    diagonals = set()\n",
    "    \n",
    "    for cell_id in cell_list:\n",
    "        edge_union = s2.CellUnion(cell_id.get_edge_neighbors())\n",
    "        for_vertex = s2.Cell(cell_id)\n",
    "        s2connections = [(for_vertex.get_vertex(0), for_vertex.get_vertex(1)), (for_vertex.get_vertex(0), for_vertex.get_vertex(2)), (for_vertex.get_vertex(0), for_vertex.get_vertex(3)), (for_vertex.get_vertex(1), for_vertex.get_vertex(2)), (for_vertex.get_vertex(1), for_vertex.get_vertex(3)), (for_vertex.get_vertex(2), for_vertex.get_vertex(3))]\n",
    "        latlngconnections = [(toUsableLatLng(connection[0]), toUsableLatLng(connection[1])) for connection in s2connections]\n",
    "        midpointsets = [midpointSet(connection[0], connection[1]) for connection in latlngconnections]\n",
    "        checking = [any([edge_union.contains(toS2pt(mdpt)) for mdpt in theset]) for theset in midpointsets]\n",
    "        \n",
    "        print(checking)\n",
    "        \n",
    "        for i, t_or_f in enumerate(checking):\n",
    "            if t_or_f:\n",
    "                edges.add((latlngconnections[i][0], latlngconnections[i][1]))\n",
    "                edges.add((latlngconnections[i][1], latlngconnections[i][0]))\n",
    "            else:\n",
    "                diagonals.add((latlngconnections[i][0], latlngconnections[i][1]))\n",
    "                diagonals.add((latlngconnections[i][1], latlngconnections[i][0]))\n",
    "    return edges, diagonals\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss =s2.Cell(s2.CellId.from_token('47097baa5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point: (0.6152166683865878, 0.15686615758776876, 0.772593981042408)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sss.get_center()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alledgesanddiagonals([s2.CellId.from_token('a00000007'), s2.CellId.from_token('47097baa5')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Point: (0.9999999989651402, 2.034536250313694e-05, 4.069134588798965e-05),\n",
       " Point: (0.9999999991721071, 0.0, 4.0691345896411415e-05),\n",
       " Point: (0.9999999995860662, 2.0345362515769904e-05, 2.0345362515769904e-05),\n",
       " Point: (0.9999999997930331, 0.0, 2.034536251998072e-05)}"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edgenbrscorners.difference(coordcorners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Point: (0.9999999989651402, 2.034536250313694e-05, 4.069134588798965e-05),\n",
       " Point: (0.9999999991721071, 0.0, 4.0691345896411415e-05),\n",
       " Point: (0.9999999995860662, 2.0345362515769904e-05, 2.0345362515769904e-05),\n",
       " Point: (0.9999999997930331, 0.0, 2.034536251998072e-05)}"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordcorners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point: (0.5773659305790212, -0.577318945136258, -0.5773659305790212)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f0.get_vertex(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = f0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.7510687064086356e-05, 1.7510883016982806e-05, 1.1074584459938347e-05, 1.1074809766996796e-05, 2.3492980276351833e-05, 1.75108295808397e-05]\n",
      "1\n",
      "\n",
      "[1.7510526772395676e-05, 1.7510758328043284e-05, 1.1074190140779485e-05, 1.1074415461623439e-05, 2.3492462494978592e-05, 1.75106692751899e-05]\n",
      "0\n",
      "\n",
      "[1.7510687064086356e-05, 1.107517592634038e-05, 1.751038427011923e-05, 1.7510384256564735e-05, 3.322372519689939e-05, 1.751068708538664e-05]\n",
      "1\n",
      "\n",
      "[1.1074584459938347e-05, 1.7510883016982806e-05, 1.7510687064086356e-05, 1.75108295808397e-05, 2.3492980276351833e-05, 1.1074809766996796e-05]\n",
      "0\n",
      "\n",
      "[1.1074190140779485e-05, 1.7510758328043284e-05, 1.7510526772395676e-05, 1.75106692751899e-05, 2.3492462494978592e-05, 1.1074415461623439e-05]\n",
      "1\n",
      "\n",
      "[1.751038427011923e-05, 1.107517592634038e-05, 1.7510687064086356e-05, 1.751068708538664e-05, 3.322372519689939e-05, 1.7510384256564735e-05]\n",
      "0\n",
      "\n",
      "[1.7510687064086356e-05, 1.107517592634038e-05, 1.751038427011923e-05, 1.7510384256564735e-05, 3.322372519689939e-05, 1.751068708538664e-05]\n",
      "1\n",
      "\n",
      "[1.751038427011923e-05, 1.107517592634038e-05, 1.7510687064086356e-05, 1.751068708538664e-05, 3.322372519689939e-05, 1.7510384256564735e-05]\n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for theface in [f0,f1,f2,f3,f4,f5,f6,f7]:\n",
    "    print([dist(theface.get_vertex(0), theface.get_vertex(1)), dist(theface.get_vertex(0), theface.get_vertex(2)), dist(theface.get_vertex(0), theface.get_vertex(3)), dist(theface.get_vertex(1), theface.get_vertex(2)), dist(theface.get_vertex(1), theface.get_vertex(3)), dist(theface.get_vertex(2), theface.get_vertex(3))])\n",
    "    print(theface.orientation())\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(x,y):\n",
    "    return math.hypot(y[0]-x[0],y[1]-x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f7.face()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbb.face()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.732533929229046e-05,\n",
       " 2.0964529538994757e-05,\n",
       " 1.9872674188048066e-05,\n",
       " 1.9872995603198868e-05,\n",
       " 3.08330805243693e-05,\n",
       " 1.7325237034315364e-05]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dist(bba.get_vertex(0), bba.get_vertex(1)), dist(bba.get_vertex(0), bba.get_vertex(2)), dist(bba.get_vertex(0), bba.get_vertex(3)), dist(bba.get_vertex(1), bba.get_vertex(2)), dist(bba.get_vertex(1), bba.get_vertex(3)), dist(bba.get_vertex(2), bba.get_vertex(3))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.7325441555519647e-05,\n",
       " 2.0964236144504224e-05,\n",
       " 1.9872882739906703e-05,\n",
       " 1.987320414803462e-05,\n",
       " 3.0833663761610875e-05,\n",
       " 1.732533929229046e-05]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dist(bbb.get_vertex(0), bbb.get_vertex(1)), dist(bbb.get_vertex(0), bbb.get_vertex(2)), dist(bbb.get_vertex(0), bbb.get_vertex(3)), dist(bbb.get_vertex(1), bbb.get_vertex(2)), dist(bbb.get_vertex(1), bbb.get_vertex(3)), dist(bbb.get_vertex(2), bbb.get_vertex(3))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.751038427011923e-05,\n",
       " 1.107517592634038e-05,\n",
       " 1.7510687064086356e-05,\n",
       " 1.751068708538664e-05,\n",
       " 3.322372519689939e-05,\n",
       " 1.7510384256564735e-05]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dist(aaa.get_vertex(0), aaa.get_vertex(1)), dist(aaa.get_vertex(0), aaa.get_vertex(2)), dist(aaa.get_vertex(0), aaa.get_vertex(3)), dist(aaa.get_vertex(1), aaa.get_vertex(2)), dist(aaa.get_vertex(1), aaa.get_vertex(3)), dist(aaa.get_vertex(2), aaa.get_vertex(3))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.7510384268232458e-05,\n",
       " 1.1074809779652416e-05,\n",
       " 1.7510384268232458e-05,\n",
       " 1.751038427011923e-05,\n",
       " 3.3223528069145794e-05,\n",
       " 1.751038427011923e-05]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dist(aab.get_vertex(0), aab.get_vertex(1)), dist(aab.get_vertex(0), aab.get_vertex(2)), dist(aab.get_vertex(0), aab.get_vertex(3)), dist(aab.get_vertex(1), aab.get_vertex(2)), dist(aab.get_vertex(1), aab.get_vertex(3)), dist(aab.get_vertex(2), aab.get_vertex(3))]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
