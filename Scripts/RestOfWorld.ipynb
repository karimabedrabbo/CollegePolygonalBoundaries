{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from requests_aws4auth import AWS4Auth\n",
    "import json\n",
    "from elasticsearch import Elasticsearch, RequestsHttpConnection\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session()\n",
    "\n",
    "credentials = session.get_credentials()\n",
    "es_auth = AWS4Auth(credentials.access_key, credentials.secret_key, 'us-east-1', 'es', session_token=credentials.token)\n",
    "\n",
    "es_host = 'https://search-pinata-es-wtz7zmneqgtg3g7bypilta3ske.us-east-1.es.amazonaws.com' # the Amazon ES domain, including https://\n",
    "es_headers = { \"Content-Type\": \"application/json\" }\n",
    "\n",
    "\n",
    "es = Elasticsearch([es_host], http_auth=es_auth, use_ssl=True, verify_certs=True, connection_class=RequestsHttpConnection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "collegeinfomapping = {'mappings': {'_doc': {'properties': {'active': {'type': 'boolean'},\n",
    "    'alias': {'type': 'completion'},\n",
    "    'ccwpath': {'type': 'geo_shape', 'precision': '100.0m'},\n",
    "    'city': {'type': 'completion', 'fields': {\n",
    "            'keyword': { \n",
    "              'type': 'keyword'\n",
    "            },\n",
    "            'text': { \n",
    "              'type': 'text'\n",
    "            },\n",
    "          }},\n",
    "    'cover16s': {'type': 'keyword'},\n",
    "    'fulltime': {'type': 'integer'},\n",
    "    'headcount': {'type': 'integer'},\n",
    "    'name': {'type': 'completion', 'fields': {\n",
    "            'keyword': { \n",
    "              'type': 'keyword'\n",
    "            },\n",
    "            'text': { \n",
    "              'type': 'text'\n",
    "            },\n",
    "          }},\n",
    "    'asciiName': {'type': 'completion', 'fields': {\n",
    "            'keyword': { \n",
    "              'type': 'keyword'\n",
    "            },\n",
    "            'text': { \n",
    "              'type': 'text'\n",
    "            },\n",
    "          }},\n",
    "    'location': {'type': 'geo_point'},\n",
    "    'regex': {'type': 'completion'},\n",
    "    'state': {'type': 'text'},\n",
    "    'combined': {'type': 'completion'},\n",
    "    'undergraduate': {'type': 'integer'},\n",
    "    'unitid': {'type': 'keyword'},\n",
    "    'countryCode': {'type': 'keyword'},\n",
    "    'schoolType': {'type': 'keyword'},\n",
    "    'region': {'type': 'text'},\n",
    "    'regionAscii': {'type': 'text'},\n",
    "    'subregion': {'type': 'text'},\n",
    "    'subregionAscii': {'type': 'text'},\n",
    "    'timezone': {'type': 'keyword'},\n",
    "    'urbanization': {'type': 'keyword'},\n",
    "    'zipcode': {'type': 'keyword'}}}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from requests_aws4auth import AWS4Auth\n",
    "import json\n",
    "from elasticsearch import Elasticsearch, RequestsHttpConnection\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('geonames2.json', 'r', encoding='utf8') as read_file:\n",
    "    geonames = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('newusindex9.json', 'r', encoding='utf8') as read_file:\n",
    "    univcells = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('esusindex.json', 'r', encoding='utf8') as read_file:\n",
    "    totallistworld = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timezonedict = {}\n",
    "# for nel in geonames:\n",
    "#     if nel['country-code'] == 'US':\n",
    "#         if timezonedict.get(nel['timezone']):\n",
    "#             timezonedict[nel['timezone']].append(((nel['timezone'],  nel['name'], nel['latitude'], nel['longitude'])))\n",
    "#         else:\n",
    "#             timezonedict[nel['timezone']] = [(nel['timezone'], nel['name'], nel['latitude'], nel['longitude'])]\n",
    "# timezonelist = [subel for el in list(timezonedict.values()) for subel in el]\n",
    "\n",
    "# for nel in univcells:\n",
    "#     if nel['alias']:\n",
    "#         newalias = []\n",
    "#         for elalias in nel['alias'].split('|'):\n",
    "#             if elalias:\n",
    "#                 newalias.append(elalias)\n",
    "#         nel['alias'] = newalias\n",
    "#     new = {}    \n",
    "    \n",
    "#     #for all\n",
    "#     new['active'] = True\n",
    "#     new['countryCode'] = 'US'\n",
    "    \n",
    "#     if nel['headcount']:\n",
    "#         new['headcount'] = int(nel['headcount'])\n",
    "#     if nel['fulltime']:\n",
    "#         new['fulltime'] = int(nel['fulltime'])\n",
    "#     if nel['undergraduate']:\n",
    "#         new['undergraduate'] = int(nel['undergraduate'])\n",
    "        \n",
    "#     #must\n",
    "#     new['location'] = {'lat': float(nel['latitude']), 'lon': float(nel['longitude'])}\n",
    "#     new['unitid'] = nel['unitid']\n",
    "    \n",
    "    \n",
    "#     if nel['alias']:\n",
    "#         new['alias'] = nel['alias']\n",
    "#     if nel['city']:\n",
    "#         new['city'] = nel['city']\n",
    "#     if nel['state']:\n",
    "#         new['state'] = nel['state']\n",
    "#     if nel['zipcode']:\n",
    "#         new['zipcode'] = nel['zipcode']\n",
    "#     if nel['urbanization']:\n",
    "#         new['urbanization'] = nel['urbanization']\n",
    "    \n",
    "#     if nel['countycode']:\n",
    "#         new['region'] = nel['countycode']\n",
    "#         new['regionAscii'] = nel['countycode']\n",
    "#     elif nel['countyname']:\n",
    "#         new['region'] = nel['countyname']\n",
    "#         new['regionAscii'] = nel['countyname']\n",
    "    \n",
    "#     if nel['countyname']:\n",
    "#         new['subregion'] = nel['countyname']\n",
    "#         new['subregionAscii'] = nel['countyname']\n",
    "    \n",
    "#     if 'university' in nel['regex']:\n",
    "#         new['schoolType'] = 'UNIV'\n",
    "#     elif 'college' in nel['regex']:\n",
    "#         new['schoolType'] = 'SCHC'\n",
    "#     else:\n",
    "#         new['schoolType'] = 'SCHU'\n",
    "    \n",
    "#     if not nel.get('estimated') and nel.get('cover16s'):\n",
    "#         totalpath = []\n",
    "#         for island in nel['islands']:\n",
    "#             newislandpath = []\n",
    "#             for thetuple in island['ccwpath']:\n",
    "#                 newislandpath.append([thetuple[1], thetuple[0]])\n",
    "#             totalpath.append([newislandpath])\n",
    "#         new['ccwpath'] = {'type': 'multipolygon', 'coordinates': totalpath}\n",
    "#         new['cover16s'] = nel['cover16s']\n",
    "    \n",
    "#     if nel['institution']:\n",
    "#         new['name'] = nel['institution']\n",
    "#         new['asciiName'] = nel['institution']\n",
    "#     if nel['regex']:\n",
    "#         new['regex'] = nel['regex']\n",
    "    \n",
    "#     combined = []\n",
    "   \n",
    "#     if nel['institution']:\n",
    "#         combined.append(nel['institution'])\n",
    "#     if nel['alias']:\n",
    "#         combined.extend(nel['alias'])\n",
    "        \n",
    "#     if combined:\n",
    "#         new['combined'] = combined\n",
    "    \n",
    "#     mintime = None\n",
    "#     mindist = 10000000000000000000.0\n",
    "#     def distance(p0, p1):\n",
    "#         import math\n",
    "#         return math.sqrt((p0[0] - p1[0])**2 + (p0[1] - p1[1])**2)\n",
    "\n",
    "#     for timeel in timezonelist:\n",
    "#         thedist = distance((float(nel['latitude']), float(nel['longitude'])), (float(timeel[2]), float(timeel[3])))\n",
    "#         if thedist < mindist:\n",
    "#             mindist = thedist\n",
    "#             mintime = timeel[0]\n",
    "\n",
    "#     if mintime:\n",
    "#         new['timezone'] = mintime\n",
    "    \n",
    "#     totallistworld.append(new)\n",
    "# #     es.create(index= 'college-info', id=nel['unitid'], doc_type='_doc', body=new)\n",
    "# #     time.sleep(.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(totallistworld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6780"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(totallistworld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idset = set()\n",
    "for nel in univcells:\n",
    "    idset.add(nel['unitid'])\n",
    "for nel in geonames:\n",
    "    if nel['geonameid'] in idset:\n",
    "        nel['geonameid'] = nel['geonameid'] + '_' + '1'\n",
    "for nel in geonames:\n",
    "    if 'US' != nel['country-code'] and (nel['feature-code'] == 'SCHC' or nel['feature-code'] == 'UNIV'):\n",
    "        new = {}\n",
    "        if nel['alternatenames']:\n",
    "            newalias = []\n",
    "            for elalias in nel['alternatenames'].split(','):\n",
    "                if elalias:\n",
    "                    newalias.append(elalias)\n",
    "            nel['alternatenames'] = newalias\n",
    "        \n",
    "        #all\n",
    "        new['active'] = True\n",
    "        \n",
    "        #must\n",
    "        new['location'] = {'lat': float(nel['latitude']), 'lon': float(nel['longitude'])}\n",
    "        new['unitid'] = nel['geonameid']\n",
    "        \n",
    "\n",
    "        if nel.get('regionName'):\n",
    "            new['region'] = nel['regionName']\n",
    "        \n",
    "        if nel.get('regionAscii'):\n",
    "            new['regionAscii'] = nel['regionAscii']\n",
    "\n",
    "        if nel.get('subregionName'):\n",
    "            new['subregion'] = nel['subregionName']\n",
    "        \n",
    "        if nel.get('subregionAscii'):\n",
    "            new['subregionAscii'] = nel['subregionAscii']\n",
    "\n",
    "        if nel['alternatenames']:\n",
    "            new['alias'] = nel['alternatenames']\n",
    "\n",
    "        if nel['name']:\n",
    "            new['name'] = nel['name']\n",
    "            \n",
    "        if nel['asciiname']:\n",
    "            new['asciiName'] = nel['asciiname']\n",
    "\n",
    "        if nel['timezone']:\n",
    "            new['timezone'] = nel['timezone']\n",
    "        \n",
    "        if nel['feature-code']:\n",
    "            new['schoolType'] = nel['feature-code']\n",
    "            \n",
    "        if nel['country-code']:\n",
    "            new['countryCode'] = nel['country-code']\n",
    "            \n",
    "        \n",
    "        combined = []\n",
    "        if nel['name']:\n",
    "            combined.append(nel['name'])\n",
    "        if nel['asciiname']:\n",
    "            combined.append(nel['asciiname'])\n",
    "        if nel['alternatenames']:\n",
    "            combined.extend(nel['alternatenames'])\n",
    "\n",
    "        if combined:\n",
    "            new['combined'] = combined\n",
    "\n",
    "        totallistworld.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11194"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(totallistworld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for finalel in totallistworld:\n",
    "    es.create(index='college-info', id=finalel['unitid'], doc_type='_doc', body=finalel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11194"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(totallistworld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['active', 'countryCode', 'headcount', 'fulltime', 'undergraduate', 'location', 'unitid', 'city', 'state', 'zipcode', 'urbanization', 'region', 'regionAscii', 'subregion', 'subregionAscii', 'schoolType', 'name', 'asciiName', 'regex', 'combined', 'timezone'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totallistworld[5000].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['active', 'location', 'unitid', 'region', 'regionAscii', 'subregion', 'alias', 'name', 'asciiName', 'timezone', 'schoolType', 'countryCode', 'combined'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totallistworld[9000].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('admin2Codes.json', 'r', encoding='utf8') as read_file:\n",
    "    admin2 = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('admin1CodesASCII.json', 'r', encoding='utf8') as read_file:\n",
    "    admin1 = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toPathDict(lst):\n",
    "    newdict = {}\n",
    "    for el in lst:\n",
    "        final=el['path'].split('.')\n",
    "        for ind, innerel in enumerate(final):\n",
    "            if innerel != '0':\n",
    "                innerel = innerel.lstrip('0')\n",
    "            final[ind] = innerel\n",
    "        newdict[('.'.join(final))] = el\n",
    "    return newdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin1 = toPathDict(admin1)\n",
    "admin2 = toPathDict(admin2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomatch =0\n",
    "last = None\n",
    "for ind, el in enumerate(geonames):\n",
    "    if el['admin2-code']:\n",
    "        search = el['country-code'] + '.' + el['admin1-code'] + '.' + el['admin2-code']\n",
    "        if search in admin2:\n",
    "            el['subregionName'] = admin2[search]['name']\n",
    "            el['subregionAscii'] = admin2[search]['asciiname']\n",
    "    if el['admin1-code']:\n",
    "        search = el['country-code'] + '.' + el['admin1-code']\n",
    "        if search in admin1:\n",
    "            el['regionName'] = admin1[search]['name']\n",
    "            el['regionAscii'] = admin1[search]['asciiname']\n",
    "    geonames[ind] = el\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "count =0\n",
    "for el in geonames:\n",
    "    if not el.get('regionName') or not el.get('regionAscii'):\n",
    "        count+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285431"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(geonames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('geonames2.json', 'w', encoding='utf8') as write_file:\n",
    "    json.dump( geonames,write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
