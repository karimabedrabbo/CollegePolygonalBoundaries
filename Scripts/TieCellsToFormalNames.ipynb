{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import s2sphere as s2\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('collegeonly.json', 'r', encoding='utf8') as read_file:\n",
    "    collegecells = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('univonly.json', 'r', encoding='utf8') as read_file:\n",
    "    univcells = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('geonames.json', 'r', encoding='utf8') as read_file:\n",
    "    geonames = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('usunivandcollegeindex.json', 'r', encoding='utf8') as read_file:\n",
    "    usindex = json.load(read_file)['elements']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToTokenDict(cell_list):\n",
    "    ldict = {}\n",
    "    for element in cell_list:\n",
    "        for token in element['cover16s']:\n",
    "            if token in ldict:\n",
    "                raise ValueError\n",
    "            else:\n",
    "                ldict[token] = element\n",
    "    return ldict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "univldict = convertToTokenDict(univcells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "collegeldict = convertToTokenDict(collegecells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21187"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(univcells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24465"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(collegecells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findspecificcode(namelist):\n",
    "    ftcode = []\n",
    "    for el in namelist:\n",
    "        if el['feature-code'] == 'UNIV':\n",
    "            ftcode.append(el)\n",
    "    return ftcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "univonlygeonames = findspecificcode(geonames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1359"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(univonlygeonames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6780"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(usindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def linkCoordinateToBound(ldicts, namelist, numexpansions=0):\n",
    "#     matched = 0\n",
    "#     unmatched = 0\n",
    "#     matchedindex = []\n",
    "#     unmatchedindex = []\n",
    "#     def expandTokens(token):\n",
    "#         instcell = s2.CellId.from_token(token)\n",
    "#         nbrs = set(map(lambda x: x.to_token(), list(instcell.get_edge_neighbors()) + [instcell]))\n",
    "#         return nbrs\n",
    "    \n",
    "#     for ldict in ldicts:\n",
    "#         for ltok in ldict:\n",
    "#             if ldict[ltok].get('matched'):\n",
    "#                 ldict[ltok].pop('matched')\n",
    "    \n",
    "    \n",
    "#     for institution in namelist:\n",
    "#         insttok = s2.CellId.from_lat_lng(s2.LatLng.from_degrees(float(institution['latitude']), float(institution['longitude']))).parent(16).to_token()\n",
    "        \n",
    "#         allnbrs = set([insttok])\n",
    "#         allmmbrs = set()\n",
    "        \n",
    "#         for expindex in range(0,numexpansions+1):\n",
    "#             for celltok in list(allnbrs):\n",
    "#                 if celltok not in allmmbrs:\n",
    "#                     if expindex != numexpansions:\n",
    "#                         thenbrs = expandTokens(celltok)\n",
    "#                         allnbrs.update(thenbrs)\n",
    "#                     allmmbrs.add(celltok)\n",
    "  \n",
    "#         somematch = False\n",
    "#         for ldict in ldicts:\n",
    "#             for exptok in allmmbrs:\n",
    "#                 coorsbound = ldict.get(exptok)\n",
    "#                 if coorsbound:\n",
    "#                     if ldict[exptok].get('matched'):\n",
    "#                         ldict[exptok]['matched'].append(institution)\n",
    "#                     else:\n",
    "#                         ldict[exptok]['matched'] = [institution]\n",
    "#                     somematch = True\n",
    "#                     break\n",
    "                    \n",
    "#         if somematch:\n",
    "#             matchedindex.append(institution)\n",
    "#             matched += 1\n",
    "#         else:\n",
    "#             unmatchedindex.append(institution)\n",
    "#             unmatched += 1\n",
    "        \n",
    "#     print(matched)\n",
    "#     print(unmatched)\n",
    "#     return matchedindex, unmatchedindex\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matched, unmatched = linkCoordinateToBound([univldict, collegeldict], usindex, numexpansions=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stufff(nameindex, celllists, selectiveness=20, numexpansions=1, clean=False):\n",
    "\n",
    "    \n",
    "    def cleanSlate():\n",
    "    \n",
    "        from nltk.corpus import stopwords\n",
    "        import string\n",
    "        from string import punctuation\n",
    "        import re\n",
    "        \n",
    "        def expandTokens(token):\n",
    "            instcell = s2.CellId.from_token(token)\n",
    "            nbrs = set(map(lambda x: x.to_token(), list(instcell.get_edge_neighbors()) + [instcell]))\n",
    "            return nbrs\n",
    "        \n",
    "        #############\n",
    "        #REMOVALS\n",
    "        for nm in nameindex:\n",
    "            for key in nm.keys():\n",
    "                if key in ['regex', 'hit10s', 'hit11s', 'hit12s', 'hit13s', 'hit14s', 'hit15s', 'hit16s', 'cover16s']:\n",
    "                    nm.pop(key)\n",
    "\n",
    "        for celllist in celllists:\n",
    "            for el in celllist:\n",
    "                for key in el.keys():\n",
    "                    if key in ['regex', 'hit10s', 'hit11s', 'hit12s', 'hit13s', 'hit14s', 'hit15s', 'hit16s']:\n",
    "                        nm.pop(key)\n",
    "\n",
    "\n",
    "        #####################\n",
    "        #HIT TOKENS\n",
    "        for celllist in celllists:\n",
    "            for el in celllist:\n",
    "                for i in range(16, 17):\n",
    "                    b = s2.CellUnion(map(lambda x: s2.CellId.from_token(x), el.get('cover16s')))\n",
    "                    b.expand(i)\n",
    "                    b.normalize()\n",
    "                    el['hit' + str(i) + 's'] = list(map(lambda x: x.to_token(), b.cell_ids()))\n",
    "\n",
    "        for nm in nameindex:\n",
    "            insttok = s2.CellId.from_lat_lng(s2.LatLng.from_degrees(float(nm['latitude']), float(nm['longitude']))).parent(16).to_token()    \n",
    "            allnbrs = set([insttok])\n",
    "            allmmbrs = set()\n",
    "\n",
    "            for expindex in range(0,numexpansions+1):\n",
    "                for celltok in list(allnbrs):\n",
    "                    if celltok not in allmmbrs:\n",
    "                        if expindex != numexpansions:\n",
    "                            thenbrs = expandTokens(celltok)\n",
    "                            allnbrs.update(thenbrs)\n",
    "                        allmmbrs.add(celltok)\n",
    "\n",
    "            for i in range(16,17):\n",
    "                a = s2.CellUnion(map(lambda x: s2.CellId.from_token(x), list(allmmbrs)))\n",
    "                a.expand(i)\n",
    "                a.normalize()\n",
    "                nm['hit' + str(i) + 's'] = list(map(lambda x: x.to_token(), a.cell_ids()))\n",
    "    \n",
    "        #######################\n",
    "        #WORDS\n",
    "        exclude = set(string.punctuation)\n",
    "        exclude.update(list(stopwords.words('english')))\n",
    "        exclude.add('')\n",
    "        r = re.compile(r'[\\s{}]+'.format(re.escape(punctuation)))\n",
    "        \n",
    "        for nm in nameindex:\n",
    "    #         splitalias = [tt for tt in (r.split(nm['alias'].lower())) if tt not in exclude]\n",
    "            splitnm = [tt for tt in (r.split(nm['institution'].lower())) if tt not in exclude]\n",
    "    #         finalwords = splitalias + splitnm\n",
    "            finalwords = splitnm\n",
    "            nm['regex'] = finalwords\n",
    "\n",
    "        for celllist in celllists:\n",
    "            for el in celllist:\n",
    "                finalwords = []\n",
    "                for onename in el['allnames']:\n",
    "                    finalwords.extend([sss.lower() for sss in r.split(onename) if sss.lower() not in exclude])\n",
    "                el['regex'] = finalwords\n",
    "\n",
    "    ##############\n",
    "    #OPERATIONS SETUP\n",
    "    def setup():\n",
    "        \n",
    "        for nm in nameindex:\n",
    "            if 'cover16s' in nm:\n",
    "                nm.pop('cover16s')\n",
    "            if 'estimated' in nm:\n",
    "                nm.pop('cover16s')\n",
    "            if 'children' in nm:\n",
    "                nm.pop('children')\n",
    "                    \n",
    "        from collections import Counter\n",
    "        \n",
    "        comprehensiveindexwords = []\n",
    "        for indexel in nameindex:\n",
    "            comprehensiveindexwords.extend(list(set(indexel['regex'])))\n",
    "\n",
    "        indexcountsdict = Counter(comprehensiveindexwords)\n",
    "\n",
    "        indexcountsvalues = list(indexcountsdict.values())\n",
    "        indexcountwords = list(indexcountsdict.keys())\n",
    "        indexcountsvalues, indexcountwords = zip(*sorted(zip(indexcountsvalues, indexcountwords)))\n",
    "\n",
    "        bannedwords = set(indexcountwords[::-1][:len(indexcountwords) // selectiveness])\n",
    "\n",
    "        \n",
    "        cellnmdict = {}\n",
    "        for celllist in celllists:\n",
    "            for el in celllist:\n",
    "                for cellregnm in el['regex']:\n",
    "                    if cellregnm in cellnmdict:\n",
    "                        if not el in cellnmdict[cellregnm]:\n",
    "                            cellnmdict[cellregnm].append(el)\n",
    "                    else:\n",
    "                        cellnmdict[cellregnm] = [el]\n",
    "\n",
    "        cellldict = {}\n",
    "        for celllist in celllists:\n",
    "            for el in celllist:\n",
    "                for hitkey in ['hit16s']:\n",
    "                    for celltok in el[hitkey]:\n",
    "                        if celltok in cellldict:\n",
    "                            if not el in cellldict[celltok]:\n",
    "                                cellldict[celltok].append(el)\n",
    "                        else:\n",
    "                            cellldict[celltok] = [el]\n",
    "        return bannedwords, cellldict, cellnmdict\n",
    "        \n",
    "    def colidebylocationidentifybyname():\n",
    "        for printindex, nm in enumerate(nameindex):\n",
    "\n",
    "    #         if printindex % 10 == 0:\n",
    "    #             print(\"printindex\")\n",
    "    #             print(printindex)\n",
    "\n",
    "            collision = []\n",
    "            for hitkey in ['hit16s']:\n",
    "                for nmtok in nm[hitkey]:\n",
    "                    possiblecollision = cellldict.get(nmtok)\n",
    "                    if possiblecollision:\n",
    "                        for elfrompossible in possiblecollision:\n",
    "                            if elfrompossible not in collision:\n",
    "                                collision.append(elfrompossible)\n",
    "\n",
    "            #added in\n",
    "            finalchoices = collision\n",
    "            if finalchoices:\n",
    "                completecover16s = set()\n",
    "                repcellid = s2.CellId.from_lat_lng(s2.LatLng.from_degrees(float(nm['latitude']), float(nm['longitude']))).parent(16).to_token()\n",
    "                for finalchoice in finalchoices:\n",
    "                    if repcellid in finalchoice['cover16s']:\n",
    "                        completecover16s.update(finalchoice['cover16s'])\n",
    "                nm['cover16s'] = list(completecover16s)\n",
    "\n",
    "#             bannedwordencounters = 0\n",
    "#             candidates = []\n",
    "#             potentialcandidates = []\n",
    "\n",
    "#             if collision:\n",
    "#                 for regnm in nm['regex']:\n",
    "#                     if regnm not in bannedwords:\n",
    "#                         if regnm in cellnmdict:\n",
    "#                             for innerel in cellnmdict[regnm]:\n",
    "#                                 if innerel in collision:\n",
    "#                                     if innerel not in candidates:\n",
    "#                                         candidates.append(innerel)\n",
    "#                     else:\n",
    "#                         if regnm in cellnmdict:\n",
    "#                             for innerel in cellnmdict[regnm]:\n",
    "#                                 if innerel in collision:\n",
    "#                                     if (regnm, innerel) not in potentialcandidates:\n",
    "#                                         potentialcandidates.append((regnm, innerel))\n",
    "#                         bannedwordencounters += 1\n",
    "\n",
    "\n",
    "#                 if bannedwordencounters == len(nm['regex']):\n",
    "#                     secondorderbannedencounters = 0\n",
    "#                     for regnm in nm['regex']:\n",
    "#                         if regnm not in secondorderbannedwords:\n",
    "#                             for pcand in potentialcandidates:\n",
    "#                                 if pcand[0] == regnm and pcand[1] not in candidates:\n",
    "#                                     candidates.append(pcand[1])\n",
    "#                         else:\n",
    "#                             secondorderbannedencounters += 1\n",
    "\n",
    "#                     if secondorderbannedencounters == bannedwordencounters:\n",
    "#                         print(\"ALL SECOND ORDER ENCOUNTERED\")\n",
    "#                         print(nm['regex'])\n",
    "#                         print()\n",
    "\n",
    "#                 secondorderexactcandidates = []\n",
    "#                 secondordersubsetcandidates = []\n",
    "#                 nmregexset = set(nm['regex'])\n",
    "#                 for cand in candidates:\n",
    "#                     candregexset = set(cand['regex'])\n",
    "#                     if candregexset == nmregexset:\n",
    "#                         secondorderexactcandidates.append(cand)\n",
    "#                     elif candregexset.issubset(nmregexset) or nmregexset.issubset(candregexset):\n",
    "#                         secondordersubsetcandidates.append(cand)\n",
    "\n",
    "#                 finalchoices = []\n",
    "#                 if len(secondorderexactcandidates) == 0 and len(secondordersubsetcandidates) == 0:\n",
    "#                     finalchoices = []\n",
    "#                 elif len(secondorderexactcandidates) == 1:\n",
    "#                     finalchoices = secondorderexactcandidates\n",
    "#                 elif len(secondorderexactcandidates) > 1:\n",
    "#                     finalchoices = secondorderexactcandidates\n",
    "#                 elif len(secondordersubsetcandidates) == 1:\n",
    "#                     finalchoices = secondordersubsetcandidates\n",
    "#                 elif len(secondordersubsetcandidates) > 1:\n",
    "#                     finalchoices = secondordersubsetcandidates\n",
    "\n",
    "#                 if finalchoices:\n",
    "#                     completecover16s = set()\n",
    "#                     repcellid = s2.CellId.from_lat_lng(s2.LatLng.from_degrees(float(nm['latitude']), float(nm['longitude']))).parent(16).to_token()\n",
    "#                     for finalchoice in finalchoices:\n",
    "#                         if repcellid in finalchoice['cover16s']:\n",
    "#                             completecover16s.update(finalchoice['cover16s'])\n",
    "#                     nm['cover16s'] = list(completecover16s)\n",
    "    \n",
    "    def makesurecoversunique():\n",
    "        restart = True\n",
    "        while restart:\n",
    "            print(\"repeat\")\n",
    "            ldictmapping = {}\n",
    "            restart = False\n",
    "            for inel in nameindex:\n",
    "                indcover16s = inel.get('cover16s', None)\n",
    "                if indcover16s:\n",
    "                    for tok16 in indcover16s:\n",
    "                        if ldictmapping.get(tok16, None):\n",
    "                            this16s = set(inel['cover16s'])\n",
    "                            ldict16s = set(ldictmapping[tok16]['cover16s'])\n",
    "                            intersection16s = ldict16s.intersection(this16s)\n",
    "                            if float(ldictmapping[tok16]['undergraduate']) >= float(inel['undergraduate']):\n",
    "                                inel['cover16s'] = list(this16s.difference(intersection16s))\n",
    "                            else:\n",
    "                                ldictmapping[tok16]['cover16s'] = list(ldict16s.difference(intersection16s))\n",
    "                            restart = True\n",
    "                            break\n",
    "                        else:\n",
    "                            ldictmapping[tok16] = inel\n",
    "                if restart:\n",
    "                    break\n",
    "                            \n",
    "    def expandpoints():         \n",
    "        justpointsfornow = []\n",
    "        for pointnm in nameindex:\n",
    "            if not pointnm.get('cover16s', None):\n",
    "                justpointsfornow.append(pointnm)\n",
    "        \n",
    "        ldictmapping = {}\n",
    "        for inel in nameindex:\n",
    "            indcover16s = inel.get('cover16s', None)\n",
    "            if indcover16s:\n",
    "                for tok16 in indcover16s:\n",
    "                    if ldictmapping.get(tok16, None):\n",
    "                        print(\"duplicate\")\n",
    "                    else:\n",
    "                        ldictmapping[tok16] = inel\n",
    "\n",
    "        import math\n",
    "        def get_cell_ids(lat, long, radius):\n",
    "            EARTH_RADIUS = 6371000  # radius of Earth in meters\n",
    "            region = s2.Cap.from_axis_angle(s2.LatLng.from_degrees(lat, long).to_point(), s2.Angle.from_degrees(360*radius/(2*math.pi*EARTH_RADIUS)))\n",
    "            coverer = s2.RegionCoverer()\n",
    "            coverer.min_level = 16\n",
    "            coverer.max_level = 16\n",
    "            coverer.max_cells = 1000\n",
    "            coverer.level_mod = 1\n",
    "            cells = coverer.get_covering(region)\n",
    "            return [x.to_token() for x in cells]\n",
    "\n",
    "        urbanizationcalc = {'City: Midsize': 2.380979060935266e-08,\n",
    "                 'City: Small': 2.378871715446322e-08,\n",
    "                 'Town: Fringe': 2.3028870479638616e-08,\n",
    "                 'Rural: Remote': 1.940241468738347e-08,\n",
    "                 'Suburb: Large': 1.998525951622446e-08,\n",
    "                 'Town: Remote': 1.8832485911217132e-08,\n",
    "                 'Town: Distant': 2.2870535568747298e-08,\n",
    "                 'Suburb: Small': 3.2827424802967285e-08,\n",
    "                 'City: Large': 1.7779747365296302e-08,\n",
    "                 'Rural: Fringe': 1.612806927185429e-08,\n",
    "                 'Rural: Distant': 1.7585095137780952e-08,\n",
    "                 'Suburb: Midsize': 3.056580135032997e-08}\n",
    "\n",
    "        tometersconstant = 40589771116743.48\n",
    "        onehundreddownplusextra = [100000, 10000, 1000, 100, 99, 98, 97, 96, 95, 94, 93, 92, 91, 90, 89, 88, 87, 86, 85, 84, 83, 82, 81, 80, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 65, 64, 63, 62, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9.9, 9.8, 9.700000000000001, 9.600000000000001, 9.500000000000002, 9.400000000000002, 9.300000000000002, 9.200000000000003, 9.100000000000003, 9.000000000000004, 8.900000000000004, 8.800000000000004, 8.700000000000005, 8.600000000000005, 8.500000000000005, 8.400000000000006, 8.300000000000006, 8.200000000000006, 8.100000000000007, 8.000000000000007, 7.9000000000000075, 7.800000000000008, 7.700000000000008, 7.6000000000000085, 7.500000000000009, 7.400000000000009, 7.30000000000001, 7.20000000000001, 7.10000000000001, 7.000000000000011, 6.900000000000011, 6.800000000000011, 6.700000000000012, 6.600000000000012, 6.500000000000012, 6.400000000000013, 6.300000000000013, 6.2000000000000135, 6.100000000000014, 6.000000000000014, 5.900000000000015, 5.800000000000015, 5.700000000000015, 5.600000000000016, 5.500000000000016, 5.400000000000016, 5.300000000000017, 5.200000000000017, 5.100000000000017, 5.000000000000018, 4.900000000000018, 4.8000000000000185, 4.700000000000019, 4.600000000000019, 4.5000000000000195, 4.40000000000002, 4.30000000000002, 4.200000000000021, 4.100000000000021, 4.000000000000021, 3.9000000000000212, 3.800000000000021, 3.700000000000021, 3.600000000000021, 3.500000000000021, 3.400000000000021, 3.3000000000000207, 3.2000000000000206, 3.1000000000000205, 3.0000000000000204, 2.9000000000000203, 2.8000000000000203, 2.70000000000002, 2.60000000000002, 2.50000000000002, 2.40000000000002, 2.30000000000002, 2.2000000000000197, 2.1000000000000196, 2.0000000000000195, 1.9000000000000195, 1.8000000000000194, 1.7000000000000193, 1.6000000000000192, 1.500000000000019, 1.400000000000019, 1.300000000000019, 1.2000000000000188, 1.1000000000000187, 1]\n",
    "#         onehundreddownplusextra = [100000, 10000, 1000, 100, 50, 10, 5, 2, 1.5, 1]\n",
    "        newcover16set = set(list(ldictmapping.keys()))\n",
    "\n",
    "        for incrementaldown in onehundreddownplusextra:\n",
    "            print(incrementaldown)\n",
    "            for nm in justpointsfornow:\n",
    "                if nm.get('urbanization', None) and nm.get('urbanization', None) in urbanizationcalc:\n",
    "                    radiustocover = (math.sqrt((tometersconstant*urbanizationcalc[nm['urbanization']]) / (math.pi))) / (incrementaldown)\n",
    "                else:\n",
    "                    radiustocover = 508.14570704546776 / incrementaldown\n",
    "                    \n",
    "                new16s = get_cell_ids(float(nm['latitude']), float(nm['longitude']), radiustocover)\n",
    "\n",
    "                \n",
    "                newcover16set.difference_update(nm.get('cover16s', set()))\n",
    "\n",
    "                if set(new16s).isdisjoint(newcover16set):\n",
    "                    newcover16set.update(nm.get('cover16s', set()))\n",
    "                    nm['cover16s'] = list(set(new16s))\n",
    "                    nm['estimated'] = True\n",
    "                    newcover16set.update(set(new16s))\n",
    "                else:\n",
    "                    newcover16set.update(nm.get('cover16s', set()))\n",
    "    \n",
    "    ########################################################\n",
    "    #MAIN\n",
    "    if clean:\n",
    "        cleanSlate()\n",
    "    \n",
    "    bannedwords, cellldict, cellnmdict = setup()\n",
    "    \n",
    "#     secondorderbannedwords = set(['college', 'university', 'school', 'institute', 'community', 'academy', 'technical', 'state', 'center', 'career', 'new', 'campus', 'county', 'american', 'san', 'city', 'education', 'international', 'south', 'valley', 'north', 'central', 'national', 'southern', 'st', 'saint', 'professional', 'western', 'west', 'careers', 'schools', 'graduate', 'northwest', 'los', 'eastern', 'de', 'east', 'area', 'pacific', 'main', 'southwest', 'district', 'america', 'studies', 'santa', 'river', 'regional', 'northern', 'united', 'mexico', 'la', 'junior', 'hills', 'bay', 'southwestern', 'mountain', 'mount', 'mary', 'le', 'colleges', 'universal', 'springs', 'lakes', 'island'])\n",
    "    secondorderbannedwords = set(['college', 'university', 'school', 'institute', 'community', 'academy', 'campus', 'colleges'])\n",
    "    \n",
    "    colidebylocationidentifybyname()\n",
    "    makesurecoversunique()\n",
    "    expandpoints()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "repeat\n",
      "100000\n",
      "10000\n",
      "1000\n",
      "100\n",
      "99\n",
      "98\n",
      "97\n",
      "96\n",
      "95\n",
      "94\n",
      "93\n",
      "92\n",
      "91\n",
      "90\n",
      "89\n",
      "88\n",
      "87\n",
      "86\n",
      "85\n",
      "84\n",
      "83\n",
      "82\n",
      "81\n",
      "80\n",
      "79\n",
      "78\n",
      "77\n",
      "76\n",
      "75\n",
      "74\n",
      "73\n",
      "72\n",
      "71\n",
      "70\n",
      "69\n",
      "68\n",
      "67\n",
      "66\n",
      "65\n",
      "64\n",
      "63\n",
      "62\n",
      "61\n",
      "60\n",
      "59\n",
      "58\n",
      "57\n",
      "56\n",
      "55\n",
      "54\n",
      "53\n",
      "52\n",
      "51\n",
      "50\n",
      "49\n",
      "48\n",
      "47\n",
      "46\n",
      "45\n",
      "44\n",
      "43\n",
      "42\n",
      "41\n",
      "40\n",
      "39\n",
      "38\n",
      "37\n",
      "36\n",
      "35\n",
      "34\n",
      "33\n",
      "32\n",
      "31\n",
      "30\n",
      "29\n",
      "28\n",
      "27\n",
      "26\n",
      "25\n",
      "24\n",
      "23\n",
      "22\n",
      "21\n",
      "20\n",
      "19\n",
      "18\n",
      "17\n",
      "16\n",
      "15\n",
      "14\n",
      "13\n",
      "12\n",
      "11\n",
      "10\n",
      "9.9\n",
      "9.8\n",
      "9.700000000000001\n",
      "9.600000000000001\n",
      "9.500000000000002\n",
      "9.400000000000002\n",
      "9.300000000000002\n",
      "9.200000000000003\n",
      "9.100000000000003\n",
      "9.000000000000004\n",
      "8.900000000000004\n",
      "8.800000000000004\n",
      "8.700000000000005\n",
      "8.600000000000005\n",
      "8.500000000000005\n",
      "8.400000000000006\n",
      "8.300000000000006\n",
      "8.200000000000006\n",
      "8.100000000000007\n",
      "8.000000000000007\n",
      "7.9000000000000075\n",
      "7.800000000000008\n",
      "7.700000000000008\n",
      "7.6000000000000085\n",
      "7.500000000000009\n",
      "7.400000000000009\n",
      "7.30000000000001\n",
      "7.20000000000001\n",
      "7.10000000000001\n",
      "7.000000000000011\n",
      "6.900000000000011\n",
      "6.800000000000011\n",
      "6.700000000000012\n",
      "6.600000000000012\n",
      "6.500000000000012\n",
      "6.400000000000013\n",
      "6.300000000000013\n",
      "6.2000000000000135\n",
      "6.100000000000014\n",
      "6.000000000000014\n",
      "5.900000000000015\n",
      "5.800000000000015\n",
      "5.700000000000015\n",
      "5.600000000000016\n",
      "5.500000000000016\n",
      "5.400000000000016\n",
      "5.300000000000017\n",
      "5.200000000000017\n",
      "5.100000000000017\n",
      "5.000000000000018\n",
      "4.900000000000018\n",
      "4.8000000000000185\n",
      "4.700000000000019\n",
      "4.600000000000019\n",
      "4.5000000000000195\n",
      "4.40000000000002\n",
      "4.30000000000002\n",
      "4.200000000000021\n",
      "4.100000000000021\n",
      "4.000000000000021\n",
      "3.9000000000000212\n",
      "3.800000000000021\n",
      "3.700000000000021\n",
      "3.600000000000021\n",
      "3.500000000000021\n",
      "3.400000000000021\n",
      "3.3000000000000207\n",
      "3.2000000000000206\n",
      "3.1000000000000205\n",
      "3.0000000000000204\n",
      "2.9000000000000203\n",
      "2.8000000000000203\n",
      "2.70000000000002\n",
      "2.60000000000002\n",
      "2.50000000000002\n",
      "2.40000000000002\n",
      "2.30000000000002\n",
      "2.2000000000000197\n",
      "2.1000000000000196\n",
      "2.0000000000000195\n",
      "1.9000000000000195\n",
      "1.8000000000000194\n",
      "1.7000000000000193\n",
      "1.6000000000000192\n",
      "1.500000000000019\n",
      "1.400000000000019\n",
      "1.300000000000019\n",
      "1.2000000000000188\n",
      "1.1000000000000187\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "stufff(usindex, [collegecells, univcells],clean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('newusindex8.json', 'w', encoding='utf8') as write_file:\n",
    "    json.dump(usindex, write_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import s2sphere as s2\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('newusindex7.json', 'r', encoding='utf8') as read_file:\n",
    "    usindex = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in usindex:\n",
    "    if 'marked' in el:\n",
    "        el.pop('marked')\n",
    "    if 'hit16s' in el:\n",
    "        el.pop('hit16s')\n",
    "    if el.get('cover16s') == []:\n",
    "        el.pop('cover16s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalldictmapping = {}\n",
    "for inel in usindex:\n",
    "    indcover16s = inel.get('cover16s', None)\n",
    "    if indcover16s:\n",
    "        for tok16 in indcover16s:\n",
    "            if finalldictmapping.get(tok16, None):\n",
    "                print(\"duplicate\")\n",
    "            else:\n",
    "                finalldictmapping[tok16] = inel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['American Baptist Seminary of the West',\n",
       " 'American Conservatory Theater',\n",
       " 'Associated Technical College-Los Angeles',\n",
       " 'Church Divinity School of the Pacific',\n",
       " 'Claremont Graduate University',\n",
       " 'Claremont McKenna College',\n",
       " 'Western University of Health Sciences',\n",
       " 'Fuller Theological Seminary',\n",
       " 'Graduate Theological Union',\n",
       " 'Harvey Mudd College',\n",
       " \"Lyle's College of Beauty\",\n",
       " 'Modern Beauty Academy',\n",
       " 'North-West College-Pasadena',\n",
       " 'Hope International University',\n",
       " 'Pacific School of Religion',\n",
       " 'Pacific States University',\n",
       " 'Pitzer College',\n",
       " 'Starr King School for the Ministry',\n",
       " 'Marshall B Ketchum University',\n",
       " 'Claremont School of Theology',\n",
       " 'Berkeley City College',\n",
       " 'The Wright Institute',\n",
       " 'Community College of Denver',\n",
       " 'Iliff School of Theology',\n",
       " 'Naropa University',\n",
       " 'Charter Oak State College',\n",
       " 'Pontifical Faculty of the Immaculate Conception at the Dominican House of Studies',\n",
       " 'Strayer University-District of Columbia',\n",
       " 'Trinity Washington University',\n",
       " 'Embry-Riddle Aeronautical University-Daytona Beach',\n",
       " 'Trinity International University-Florida',\n",
       " 'Atlanta Metropolitan State College',\n",
       " 'Morehouse College',\n",
       " 'Morehouse School of Medicine',\n",
       " 'Hawaii Institute of Hair Design',\n",
       " 'Adler University',\n",
       " 'American Academy of Art',\n",
       " 'Bethany Theological Seminary',\n",
       " 'Chicago Theological Seminary',\n",
       " 'Coyne College',\n",
       " 'East-West University',\n",
       " 'Garrett-Evangelical Theological Seminary',\n",
       " 'Harrington College of Design',\n",
       " 'Illinois College of Optometry',\n",
       " 'Institute for Clinical Social Work',\n",
       " 'The John Marshall Law School',\n",
       " 'Lutheran School of Theology at Chicago',\n",
       " 'MacCormac College',\n",
       " 'McCormick Theological Seminary',\n",
       " 'Meadville Lombard Theological School',\n",
       " 'Roosevelt University',\n",
       " 'Spertus College',\n",
       " 'Taylor Business Institute',\n",
       " 'Telshe Yeshiva-Chicago',\n",
       " 'VanderCook College of Music',\n",
       " 'La James International College-Iowa City',\n",
       " 'Concorde Career College-Kansas City',\n",
       " 'Asbury Theological Seminary',\n",
       " 'Baton Rouge School of Computers',\n",
       " 'Loyola University New Orleans',\n",
       " 'Pineville Beauty School',\n",
       " 'Maryland Beauty Academy',\n",
       " 'Notre Dame of Maryland University',\n",
       " 'Andover Newton Theological School',\n",
       " 'Empire Beauty School-Boston',\n",
       " 'Emmanuel College',\n",
       " 'Fisher College',\n",
       " 'Massachusetts College of Art and Design',\n",
       " 'The New England Conservatory of Music',\n",
       " \"Saint John's Seminary\",\n",
       " 'Simmons College',\n",
       " 'Wheelock College',\n",
       " 'College for Creative Studies',\n",
       " 'Michigan State University-College of Law',\n",
       " 'Western Theological Seminary',\n",
       " 'Augsburg University',\n",
       " 'The Art Institutes International-Minnesota',\n",
       " 'Mayo Clinic School of Medicine',\n",
       " 'Mayo Clinic School of Health Sciences',\n",
       " 'Aquinas Institute of Theology',\n",
       " 'Central Methodist University-College of Liberal Arts and Sciences',\n",
       " 'Fontbonne University',\n",
       " 'Harris-Stowe State University',\n",
       " 'Rockhurst University',\n",
       " 'University of Providence',\n",
       " 'Clarkson College',\n",
       " 'Adult and Continuing Education-BCTS',\n",
       " 'JFK Muhlenberg Harold B & Dorothy A Snyder Schools-School of Imaging',\n",
       " 'New Brunswick Theological Seminary',\n",
       " 'New Jersey Institute of Technology',\n",
       " 'St Francis Medical Center-School of Radiologic Technology',\n",
       " 'Albany Law School',\n",
       " 'Alfred University',\n",
       " 'American Academy of Dramatic Arts-New York',\n",
       " 'Joffrey Ballet School',\n",
       " 'Bank Street College of Education',\n",
       " 'Barnard College',\n",
       " 'Berk Trade and Business School',\n",
       " 'Beth Hamedrash Shaarei Yosher Institute',\n",
       " \"St Paul's School of Nursing-Queens\",\n",
       " 'Weill Cornell Medical College',\n",
       " 'Pomeroy College of Nursing at Crouse Hospital',\n",
       " 'Brittany Beauty Academy',\n",
       " 'Institute of Audio Research',\n",
       " 'Jewish Theological Seminary of America',\n",
       " 'LIU Brooklyn',\n",
       " 'Manhattan School of Music',\n",
       " 'Marymount Manhattan College',\n",
       " 'Mesivta of Eastern Parkway-Yeshiva Zichron Meilech',\n",
       " 'New York Law School',\n",
       " 'New York Theological Seminary',\n",
       " 'New York School of Interior Design',\n",
       " 'Rockefeller University',\n",
       " 'Empire Beauty School-Manhattan',\n",
       " \"St. Joseph's College-New York\",\n",
       " 'SUNY College of Environmental Science and Forestry',\n",
       " 'SUNY College of Optometry',\n",
       " 'Swedish Institute a College of Health Sciences',\n",
       " 'Teachers College at Columbia University',\n",
       " 'Union Theological Seminary in the City of New York',\n",
       " 'School of Visual Arts',\n",
       " 'Wood Tobe-Coburn School',\n",
       " 'Cleveland Institute of Dental-Medical Assistants-Cleveland',\n",
       " 'Cleveland Institute of Music',\n",
       " 'Columbus College of Art and Design',\n",
       " 'Hebrew Union College-Jewish Institute of Religion',\n",
       " 'Kent State University at Stark',\n",
       " 'Ohio State University-Mansfield Campus',\n",
       " 'Ohio State University-Marion Campus',\n",
       " 'Ohio State University-Newark Campus',\n",
       " 'Ohio University-Zanesville Campus',\n",
       " 'Trinity Lutheran Seminary',\n",
       " 'Winebrenner Theological Seminary',\n",
       " 'Beau Monde College of Hair Design',\n",
       " 'Northwest Christian University',\n",
       " 'Cabrini University',\n",
       " 'Carnegie Mellon University',\n",
       " 'Pennsylvania State University-Dickinson Law',\n",
       " 'Hussian College School of Art',\n",
       " 'Lancaster Theological Seminary',\n",
       " 'Brightwood Career Institute-Philadelphia',\n",
       " 'University of Pennsylvania',\n",
       " 'Saint Vincent Seminary',\n",
       " 'Washington Hospital School of Radiologic Technology',\n",
       " 'Rhode Island School of Design',\n",
       " 'Allen University',\n",
       " 'Claflin University',\n",
       " 'University of South Carolina-Sumter',\n",
       " 'Voorhees College',\n",
       " 'Sioux Falls Seminary',\n",
       " 'Avera Sacred Heart Hospital',\n",
       " 'University of Sioux Falls',\n",
       " 'Pentecostal Theological Seminary',\n",
       " 'Meharry Medical College',\n",
       " 'Austin Presbyterian Theological Seminary',\n",
       " 'Dallas Theological Seminary',\n",
       " 'University of Houston-Victoria',\n",
       " 'Covenant School of Nursing and Allied Health',\n",
       " 'Trinity University',\n",
       " 'Evans Hairstyling College-St George',\n",
       " 'Stevens-Henager College',\n",
       " \"Bon Secours St Mary's Hospital School of Medical Imaging\",\n",
       " 'Virginia Military Institute',\n",
       " 'Northwest University',\n",
       " 'West Virginia Junior College-Morgantown',\n",
       " 'Wood County School of Practical Nursing',\n",
       " 'University of Wisconsin Colleges',\n",
       " 'Educational Technical College-Recinto de Bayamon',\n",
       " 'Instituto de Educacion Tecnica Ocupacional La Reine-Manati',\n",
       " 'International Technical College',\n",
       " 'Liceo de Arte y Tecnologia',\n",
       " 'Modern Hairstyling Institute-Bayamon',\n",
       " 'Seminario Evangelico de Puerto Rico',\n",
       " 'ICPR Junior College-General Institutional',\n",
       " 'Georgia State University-Perimeter College',\n",
       " 'Cortiva Institute-Chicago',\n",
       " 'Bais Medrash Elyon',\n",
       " 'Tennessee College of Applied Technology Nashville',\n",
       " 'Branford Hall Career Institute-Jersey City',\n",
       " 'Douglas J Aveda Institute',\n",
       " 'California Career School',\n",
       " 'University of the District of Columbia-David A Clarke School of Law',\n",
       " 'The Art Institute of New York City',\n",
       " 'Mayo Clinic Graduate School of Biomedical Sciences',\n",
       " 'Argosy University-Hawaii',\n",
       " 'North-West College-Glendale',\n",
       " 'Remington College-Honolulu Campus',\n",
       " 'Kiamichi Technology Center-Poteau',\n",
       " 'Vista College-Online',\n",
       " 'Valley College-Martinsburg',\n",
       " 'Colorado School of Traditional Chinese Medicine',\n",
       " 'Inter American University of Puerto Rico-School of Optometry',\n",
       " 'Franklin Technology-MSSU',\n",
       " 'Roger Williams University School of Law',\n",
       " 'Charles Stuart School of Diamond Setting',\n",
       " 'Argosy University-Schaumburg',\n",
       " 'Eastern International College-Jersey City',\n",
       " 'Advantage Technical College',\n",
       " 'Nova College de Puerto Rico',\n",
       " 'Urban College of Boston',\n",
       " 'Studio Jewelers',\n",
       " 'Mercy Hospital School of Nursing',\n",
       " 'Brightwood College-San Antonio-Ingram',\n",
       " 'LIU Hudson at Westchester',\n",
       " 'Blessing Hospital School of Medical Laboratory Technology',\n",
       " 'New Professions Technical Institute',\n",
       " 'Argosy University-Phoenix',\n",
       " 'Linfield College-Online and Continuing Education',\n",
       " 'Milan Institute-San Antonio Ingram',\n",
       " 'IVAEM College',\n",
       " 'Argosy University-Seattle',\n",
       " 'Cascadia College',\n",
       " 'Atlantic Institute of Oriental Medicine',\n",
       " 'Bennett Career Institute',\n",
       " 'Northeastern Seminary',\n",
       " 'Southwest Skill Center-Campus of Estrella Mountain Community College',\n",
       " 'Southern University Law Center',\n",
       " 'The Seattle School of Theology & Psychology',\n",
       " 'Caribbean Forensic and Technical College',\n",
       " 'Lamar Institute of Technology',\n",
       " 'Antioch University-PhD Program in Leadership and Change',\n",
       " 'Pacific College of Oriental Medicine-Chicago',\n",
       " 'P C Age-Jersey City',\n",
       " 'Pierpont Community and Technical College',\n",
       " 'Colorado Media School',\n",
       " 'Bexley Hall Seabury Western Theological Seminary Federation, Inc.',\n",
       " 'Altierus Career College-Tacoma',\n",
       " 'Bayamon Community College',\n",
       " 'Leston College',\n",
       " 'Flagler College-Tallahassee',\n",
       " 'Toyota Technological Institute at Chicago',\n",
       " 'University of Phoenix-Kentucky',\n",
       " 'Neumont College of Computer Science',\n",
       " 'Soma Institute-The National School of Clinical Massage Therapy',\n",
       " 'Evergreen Beauty and Barber College-Everett',\n",
       " 'Sanford-Brown College-Las Vegas',\n",
       " 'Sanford-Brown College-Seattle',\n",
       " 'Daytona College',\n",
       " 'Carsten Institute of Cosmetology',\n",
       " 'Seacoast Career School-Manchester Campus',\n",
       " 'Texas Health School',\n",
       " 'Educational Technical College-Recinto de san Sebastian',\n",
       " 'Ace Institute of Technology',\n",
       " 'American Institute of Medical Technology',\n",
       " 'Averett University-Non-Traditional Programs',\n",
       " 'The Art Institute of Salt Lake City',\n",
       " 'Fortis Institute-Baltimore',\n",
       " 'Brite Divinity School',\n",
       " 'Argosy University-Nashville',\n",
       " 'Carrington College-Stockton',\n",
       " 'Instituto Educativo Premier',\n",
       " 'Charleston School of Law',\n",
       " 'Southwest University at El Paso',\n",
       " 'The Art Institute of Pittsburgh-Online Division',\n",
       " 'Chamberlain University-Ohio',\n",
       " 'Chamberlain University-Arizona',\n",
       " 'Ottawa University-Online',\n",
       " 'Professional Hands Institute',\n",
       " 'The Chicago School of Professional Psychology at Irvine',\n",
       " 'Dorsey Business Schools-Roseville Culinary Academy',\n",
       " 'Pontifical John Paul II Institute for Studies on Marriage and Family',\n",
       " 'Argosy University-Phoenix Online Division',\n",
       " 'San Diego Culinary Institute',\n",
       " 'Academy for Jewish Religion-California',\n",
       " 'Summit Salon Academy-Gainesville',\n",
       " 'Paul Mitchell the School-Chicago',\n",
       " 'The Chicago School of Professional Psychology at Washington DC',\n",
       " 'California University of Management and Sciences',\n",
       " 'Illinois Media School-Chicago Campus',\n",
       " 'Johnson & Wales University-Online',\n",
       " 'Brittany Beauty Academy',\n",
       " 'Tribeca Flashpoint College',\n",
       " 'The Collective School Of Music',\n",
       " 'Manhattan Institute',\n",
       " 'Atelier Esthetique Institute of Esthetics',\n",
       " 'Carrington College-Pomona',\n",
       " 'South University-Accelerated Graduate Programs',\n",
       " 'Aveda Institute-Los Angeles',\n",
       " 'Relay Graduate School of Education',\n",
       " 'South UniversitySavannah Online',\n",
       " 'Whitworth University-Adult Degree Programs',\n",
       " 'American Broadcasting School-Online Program',\n",
       " 'Springfield College-School of Professional and Continuing Studies',\n",
       " 'Catholic Distance University',\n",
       " \"Christie's Education\",\n",
       " 'Stella and Charles Guttman Community College',\n",
       " 'Vogue College of Cosmetology-San Antonio Fredericksburg',\n",
       " 'Aveda Institute-Tucson',\n",
       " 'Cortiva Institute-Seattle',\n",
       " 'Pennsylvania State University-World Campus',\n",
       " 'Elizabethtown College School of Continuing and Professional Studies',\n",
       " 'Florida Institute of Technology-Online',\n",
       " 'College of the Muscogee Nation',\n",
       " 'Rizzieri Institute',\n",
       " 'DeVry College of New York',\n",
       " 'DeVry University-Indiana',\n",
       " 'DeVry University-Tennessee',\n",
       " 'DeVry University-Virginia',\n",
       " 'Northeastern University Professional Advancement Network',\n",
       " 'Alexander Paul Institute of Hair Design',\n",
       " 'Park Place Premier Barber School',\n",
       " 'University of Florida-Online',\n",
       " 'University of Phoenix-Oklahoma',\n",
       " 'University of Phoenix-Pennsylvania',\n",
       " 'Tint School of Makeup & Cosmetology-Seattle',\n",
       " 'National American University-Houston',\n",
       " 'Fred D. Learey Technical College',\n",
       " 'Associated Barber College of San Diego',\n",
       " 'Antioch University Online',\n",
       " 'Theatre of Arts',\n",
       " 'Culinary Tech Center',\n",
       " 'AMG School of Licensed Practical Nursing',\n",
       " 'California Jazz Conservatory',\n",
       " 'Chamberlain University-New Jersey',\n",
       " 'The Chicago School of Professional Psychology at Xavier University of Louisiana',\n",
       " 'University of Arizona-South',\n",
       " 'Aveda Institute-Madison',\n",
       " 'Garden State Science and Technology Institute',\n",
       " 'Focus Personal Training Institute',\n",
       " 'Burrell College of Osteopathic Medicine',\n",
       " 'House of Heavilin Beauty College-Academy of Beauty Professionals',\n",
       " 'Chamberlain University-North Carolina',\n",
       " 'Kaplan University-Milwaukee',\n",
       " 'Pima Medical Institute-Dillon',\n",
       " 'Health Career Institute',\n",
       " 'C. Alexander School of Cosmetology',\n",
       " 'Career Quest Learning Center-Mt. Pleasant',\n",
       " 'National American University-Garden City',\n",
       " 'Tricoci University of Beauty Culture-Janesville',\n",
       " 'University of Wisconsin-Milwaukee Flex',\n",
       " 'University of Wisconsin Colleges Flex']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[el['institution'] for el in usindex if not el.get('cover16s')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'unitid': '245892',\n",
       "  'institution': 'Antioch University-Midwest',\n",
       "  'alias': 'Antioch University McGregor',\n",
       "  'city': 'Yellow Springs',\n",
       "  'state': 'Ohio',\n",
       "  'zipcode': '45387',\n",
       "  'urbanization': 'Rural: Fringe',\n",
       "  'countycode': 'Greene County, OH',\n",
       "  'countyname': 'Greene County',\n",
       "  'longitude': '-83.908684',\n",
       "  'latitude': '39.80321',\n",
       "  'active': 'Yes',\n",
       "  'headcount': '239',\n",
       "  'undergraduate': '54',\n",
       "  'fulltime': '114',\n",
       "  'hit16s': ['8840a014d',\n",
       "   '8840a0153',\n",
       "   '8840a0155',\n",
       "   '8840a0401',\n",
       "   '8840a0403',\n",
       "   '8840a041d',\n",
       "   '8840a06a4',\n",
       "   '8840a06ac',\n",
       "   '8840a06b4',\n",
       "   '8840a06b9',\n",
       "   '8840a06bb',\n",
       "   '8840a06bd'],\n",
       "  'regex': ['antioch', 'university', 'midwest'],\n",
       "  'cover16s': []},\n",
       " {'unitid': '442392',\n",
       "  'institution': 'Antioch University-PhD Program in Leadership and Change',\n",
       "  'alias': '',\n",
       "  'city': 'Yellow Springs',\n",
       "  'state': 'Ohio',\n",
       "  'zipcode': '45387',\n",
       "  'urbanization': 'Rural: Fringe',\n",
       "  'countycode': 'Greene County, OH',\n",
       "  'countyname': 'Greene County',\n",
       "  'longitude': '-83.908684',\n",
       "  'latitude': '39.80321',\n",
       "  'active': 'Yes',\n",
       "  'headcount': '172',\n",
       "  'undergraduate': '0',\n",
       "  'fulltime': '124',\n",
       "  'hit16s': ['8840a014d',\n",
       "   '8840a0153',\n",
       "   '8840a0155',\n",
       "   '8840a0401',\n",
       "   '8840a0403',\n",
       "   '8840a041d',\n",
       "   '8840a06a4',\n",
       "   '8840a06ac',\n",
       "   '8840a06b4',\n",
       "   '8840a06b9',\n",
       "   '8840a06bb',\n",
       "   '8840a06bd'],\n",
       "  'regex': ['antioch', 'university', 'phd', 'program', 'leadership', 'change'],\n",
       "  'cover16s': []},\n",
       " {'unitid': '482334',\n",
       "  'institution': 'National American University-Richardson',\n",
       "  'alias': '',\n",
       "  'city': 'Richardson',\n",
       "  'state': 'Texas',\n",
       "  'zipcode': '75080-5400',\n",
       "  'urbanization': 'City: Midsize',\n",
       "  'countycode': 'Dallas County, TX',\n",
       "  'countyname': 'Dallas County',\n",
       "  'longitude': '-96.768201',\n",
       "  'latitude': '32.95518',\n",
       "  'active': 'Yes',\n",
       "  'headcount': '338',\n",
       "  'undergraduate': '338',\n",
       "  'fulltime': '106',\n",
       "  'hit16s': ['864c21b87',\n",
       "   '864c21b89',\n",
       "   '864c21b8b',\n",
       "   '864c21c0b',\n",
       "   '864c21c0d',\n",
       "   '864c21c13',\n",
       "   '864c21c63',\n",
       "   '864c21c65',\n",
       "   '864c21c67',\n",
       "   '864c21c6c',\n",
       "   '864c21c74',\n",
       "   '864c21c7c'],\n",
       "  'regex': ['national', 'american', 'university', 'richardson']}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[innn for inddd, innn in enumerate([el for el in usindex if not el.get('cover16s')]) if inddd in [177,220,294]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(indd, ini) for indd, ini in enumerate([finalldictmapping[s2.CellId.from_lat_lng(s2.LatLng.from_degrees(float(el['latitude']), float(el['longitude']))).parent(16).to_token()] for el in usindex if not el.get('cover16s')]) if 'Online' in ini['institution']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True, True, True, True, True, True, True]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[inii.pop('marked') for inii in usindex if inii.get('marked', None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "restart = True\n",
    "while restart:\n",
    "    restart = False\n",
    "    \n",
    "    finalldictmapping = {}\n",
    "    for inel in usindex:\n",
    "        indcover16s = inel.get('cover16s', None)\n",
    "        if indcover16s:\n",
    "            for tok16 in indcover16s:\n",
    "                if finalldictmapping.get(tok16, None):\n",
    "                    print(\"duplicate\")\n",
    "                else:\n",
    "                    finalldictmapping[tok16] = inel\n",
    "\n",
    "\n",
    "    for inel in usindex:\n",
    "        indcover16s = inel.get('cover16s', None)\n",
    "        repcellid = s2.CellId.from_lat_lng(s2.LatLng.from_degrees(float(inel['latitude']), float(inel['longitude']))).parent(16).to_token()\n",
    "        if not indcover16s:\n",
    "            collisionss = finalldictmapping[repcellid]\n",
    "            if int(inel['undergraduate']) > int(collisionss['undergraduate']) and 'Program' not in inel['institution'] and 'Online' not in inel['institution']:\n",
    "                inel['cover16s'] = deepcopy(collisionss['cover16s'])\n",
    "                collisionss.pop('cover16s')\n",
    "                restart = True\n",
    "                break\n",
    "        elif len(indcover16s) == 1 and not inel.get('marked', False):\n",
    "            allnbrs = [inel]\n",
    "            for neighb in s2.CellId.from_token(repcellid).get_all_neighbors(16):\n",
    "                neighbor=finalldictmapping.get(neighb.to_token(), None)\n",
    "                if neighbor and neighbor not in allnbrs:\n",
    "                    allnbrs.append(neighbor)\n",
    "            \n",
    "            alloptions = allnbrs\n",
    "            bestoption = max(alloptions, key=lambda x: int(x['undergraduate']))\n",
    "            \n",
    "            popped = None\n",
    "            if 'Program' in bestoption['institution'] and 'Online' in bestoption['institution']:\n",
    "                if len(alloptions) > 1:\n",
    "                    popped = alloptions.pop(alloptions.index(bestoption))\n",
    "                    bestoption = max(alloptions, key=lambda x: int(x['undergraduate']))\n",
    "            \n",
    "            if popped:\n",
    "                alloptions.append(popped)\n",
    "                \n",
    "            newtotal16 = set()\n",
    "            \n",
    "            [newtotal16.update(el.get('cover16s', set())) for el in alloptions]\n",
    "            [el.pop('cover16s') for el in alloptions if 'cover16s' in el]\n",
    "            for rrr in alloptions:\n",
    "                rrr['marked'] = True\n",
    "            \n",
    "            bestoption['cover16s'] = list(newtotal16)\n",
    "            \n",
    "            restart=True\n",
    "            break\n",
    "            \n",
    "            \n",
    "            \n",
    "    #                 if float(neighbor['headcount']) < float(inel['headcount']) and not neighbor.get('estimated', False):\n",
    "    #                     print(neighbor['headcount'])\n",
    "    #                     print(inel['headcount'])\n",
    "\n",
    "    #                     print(neighbor['cover16s'])\n",
    "    #                     print(neighbor['institution'])\n",
    "    #         print()\n",
    "    #             inel['cover16s'] = [repcellid]\n",
    "\n",
    "    #         collisionss = finalldictmapping[repcellid]\n",
    "    #         if collisionss != inel and collisionss.get('children', None):\n",
    "    #             collisionss['children'].append(inel)\n",
    "    #             encounters.append(inel)\n",
    "    #         elif collisionss != inel:\n",
    "    #             collisionss['children'] = [inel]\n",
    "    #             encounters.append(inel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reduce' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-2a087cec2eea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mcategories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'urbanization'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotalarea\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mtotalarea\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCellId\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexact_area\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindcover16s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mcategories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'urbanization'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtotalarea\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reduce' is not defined"
     ]
    }
   ],
   "source": [
    "categories = {}\n",
    "for inel in usindex:\n",
    "    indcover16s = inel.get('cover16s', None)\n",
    "    if indcover16s:\n",
    "        if categories.get(inel['urbanization'], None):\n",
    "            totalarea = reduce(lambda x, y: x + s2.Cell(s2.CellId.from_token(y)).exact_area(), indcover16s, 0)\n",
    "            if 'Berkeley' in inel['institution'] and 'University of California' in inel['institution']:\n",
    "                print(totalarea)\n",
    "                print(s2.Cell(s2.CellId.from_token(indcover16s[0])).average_area())\n",
    "                print(len(indcover16s))\n",
    "            categories[inel['urbanization']].append(totalarea)\n",
    "        else:\n",
    "            totalarea = reduce(lambda x, y: x + s2.Cell(s2.CellId.from_token(y)).exact_area(), indcover16s, 0)\n",
    "            categories[inel['urbanization']] = [totalarea]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "19793.17 / 4.876393597557198e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_outliers(data, m=3):\n",
    "    return data[abs(data - np.mean(data)) < m * np.std(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalcategoriesarea = {}\n",
    "for catkey in categories:\n",
    "    \n",
    "    evallist = reject_outliers(np.array(categories[catkey]))\n",
    "    \n",
    "    finalcategoriesarea[catkey] = np.mean(evallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalcategoriesarea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rando16 = ['8862153d3', '886215375', '886215253', '886215343', '886215255', '88626c0c3', '88626c0df', '88626c0ab', '88626accd', '8862153c7', '88626bf53', '88621534b', '886215321', '886215311', '88621524b', '886215161', '88626c761', '88626b8bb', '88626b8ab', '88626b8a7', '88626c733', '88626bf39', '88626c74f', '88626c72b', '88626c0e5', '886215345', '886215337', '88621515d', '88626bf47', '88626c0e1', '8862153c9', '88626c0a9', '88626b8c9', '8862153a5', '88621536b', '8862153cd', '88626c717', '88626ad29', '8862153a3', '886215373', '886215313', '88626c0b5', '88626c73f', '8862153df', '8862153b1', '886215305', '88626c097', '88626c74d', '88621531d', '8862152d9', '8862153eb', '88626c769', '886215307', '88626c0d3', '886215341', '88626c0dd', '88626b8a5', '88626c76b', '8862152e3', '88621524f', '88626b8a3', '886215309', '8862152fb', '88626c0c7', '88626c737', '88626bf51', '886215249', '88626bf35', '88626c759', '886215315', '88626b8af', '8862153c3', '88626c76f', '886215339', '88626c749', '886215323', '886215303', '88626c0c9', '88626c095', '88626acd3', '8862152e7', '88626c715', '88626c719', '88626c0cb', '8862153b7', '886215165', '88626bf45', '8862152e5', '88621532f', '88626b8bd', '88626c0cd', '8862152d3', '88626c73b', '8862153d5', '88621533b', '88626c0b9', '88626c129', '88626c72f', '88621539d', '88621530f', '88626c0bf', '8862152fd', '88626c739', '88626c743', '8862153db', '8862152d7', '88626c0e7', '88626acd5', '88626b8a1', '88626c745', '8862153af', '886215251', '88626c757', '88621524d', '88626bf37', '88626c725', '88626c0b7', '88626c741', '88626b8b1', '8862153e9', '88626c735', '88626c747', '8862152f9', '88626bf49', '88626c12b', '88621515f', '886215167', '8862152e1', '886215317', '88626b8cb', '8862153b9', '88626c76d', '88621531f', '88626c0a5', '88626c127', '88626c72d', '886215163', '88626bf4b', '8862153cf', '88626c727', '88626c0d1', '88626b8b3', '88626c0ad', '88621536d', '88626c0c5', '88626ad2b', '88626c731', '88626c0db', '886215377', '88626bf4f', '88626c0bd', '88626c0a7', '88626c0d5', '88626b8cf', '886215333', '88621530b', '88621531b', '8862152db', '886215235', '88621532d', '88626c0b3', '8862153dd', '886215347', '88621530d', '88626c75d', '8862153cb', '886215349', '886215233', '886215319', '8862153bb', '88626b8b7', '8862153a1', '88626c753', '886215257', '88626c0cf', '886215325', '88626c75b', '88626c765', '88621533f', '886215237', '88626c73d', '88626c0bb', '88626bf5b', '8862153d1', '886215335', '88621534f', '88626c751', '88621532b', '88621533d', '886215329', '88626b8a9', '8862152d5', '88626bf55', '88626c755', '88626c0b1', '88626c729', '88626c0af', '8862153e1', '8862153ab', '8862153e7', '88621539f', '886215327', '88626c723', '8862153c1', '88626c0e3', '88626bf4d', '8862153d7', '886215301', '8862153b5', '8862152ff', '88626c0a3', '88626c74b', '8862153c5', '88626b8ad', '8862153b3', '88626b8b5', '88626c713', '8862153a9', '8862153d9', '88626c75f', '88626c711', '88626bf57', '88626bf59', '88626ad2d', '88626c0d7', '886215371', '88626c0d9', '88626c099', '8862152d1', '886215369', '88621536f', '886215331', '88626c0e9', '88626c767', '8862153ad', '8862153a7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randocell = s2.Cell(s2.CellId.from_token('8862153d3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.3541615507706104e-10"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randocell.exact_area()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "newunino = reduce(lambda x, y: x + s2.Cell(s2.CellId.from_token(y)).exact_area(), rando16, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0273740971752336e-07"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newunino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'cell_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-44caed9d0ae3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtotalarea\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnewunino\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcell_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'cell_ids'"
     ]
    }
   ],
   "source": [
    "totalarea = 0\n",
    "for el in newunino.cell_ids():\n",
    "    print(el.level())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geonameid': '11945546',\n",
       " 'name': 'Escola Notra Senyora de Meritxell',\n",
       " 'asciiname': 'Escola Notra Senyora de Meritxell',\n",
       " 'alternatenames': 'Escola Notra Senyora de Meritxell',\n",
       " 'latitude': '42.49727',\n",
       " 'longitude': '1.4995',\n",
       " 'feature-class': 'S',\n",
       " 'feature-code': 'SCH',\n",
       " 'country-code': 'AD',\n",
       " 'cc2': '',\n",
       " 'admin1-code': '7',\n",
       " 'admin2-code': '',\n",
       " 'admin3-code': '',\n",
       " 'admin4-code': '',\n",
       " 'population': '0',\n",
       " 'elevation': '',\n",
       " 'dem': '992',\n",
       " 'timezone': 'Europe/Andorra',\n",
       " 'modification-date': '9/8/18',\n",
       " 'hit14s': ['12a5f4c3',\n",
       "  '12a5f4dd',\n",
       "  '12a5f4df',\n",
       "  '12a5f4e4',\n",
       "  '12a5f4e9',\n",
       "  '12a5f4ef',\n",
       "  '12a5f51d',\n",
       "  '12a5f51f',\n",
       "  '12a5f521'],\n",
       " 'hit15s': ['12a5f4dd4',\n",
       "  '12a5f4ddc',\n",
       "  '12a5f4de4',\n",
       "  '12a5f4dfc',\n",
       "  '12a5f4e1',\n",
       "  '12a5f4e24',\n",
       "  '12a5f4e3c',\n",
       "  '12a5f4e44',\n",
       "  '12a5f4e7'],\n",
       " 'hit16s': ['12a5f4ddf',\n",
       "  '12a5f4de1',\n",
       "  '12a5f4de3',\n",
       "  '12a5f4e05',\n",
       "  '12a5f4e07',\n",
       "  '12a5f4e0c',\n",
       "  '12a5f4e14',\n",
       "  '12a5f4e1b',\n",
       "  '12a5f4e6b',\n",
       "  '12a5f4e6d',\n",
       "  '12a5f4e6f',\n",
       "  '12a5f4e74']}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geonames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colel in collegecells:\n",
    "    for nnn in colel['allnames']:\n",
    "        if 'Auburn' in nnn:\n",
    "            print(colel['regex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in univcells:\n",
    "    if 'matched' not in el:\n",
    "        print(el['allnames'])\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in univcells:\n",
    "    if 'matched' in el:\n",
    "        if len(el['matched']) > 1:\n",
    "            print(el['allnames'])\n",
    "            for matchedel in el['matched']:\n",
    "                print(matchedel['institution'])\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in formalnames:\n",
    "    if 'Berkeley' in name['name'] and 'University of California' in name['name']:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.CellId.from_lat_lng(s2.LatLng.from_degrees(37.87215, -122.25975)).parent(16).to_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1 = linkCoordinateToBound(locdict, formalnames, numexpansions=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2 = linkCoordinateToBound(locdict, formalnames, numexpansions=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0expansion:\n",
    "# 74232\n",
    "# 211192\n",
    "\n",
    "#1expansion:\n",
    "# 83678\n",
    "# 201746\n",
    "\n",
    "#3expansions\n",
    "# 99244\n",
    "# 186180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(locdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
